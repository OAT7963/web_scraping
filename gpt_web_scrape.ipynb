{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a0ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News row not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace the URL below with the actual URL of the web page containing the HTML\n",
    "url = 'https://finviz.com/news.ashx'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the 'tr' tag with the class 'nn'\n",
    "news_row = soup.find('td', class_='news_tooltip-tab')\n",
    "\n",
    "if news_row:\n",
    "    # Extract the different pieces of information from the news row\n",
    "    source_icon = news_row.find('td', class_='news_tooltip-tab')\n",
    "#     time_posted = news_row.find('td', class_='nn-date')\n",
    "#     news_title = news_row.find('a', class_='nn-tab-link')\n",
    "#     news_link = news_row.find('a', class_='nn-tab-link')\n",
    "\n",
    "    if source_icon:\n",
    "        print(f\"Source Icon Class: {source_icon['class']}\")\n",
    "\n",
    "    if time_posted:\n",
    "        print(f\"Time Posted: {time_posted.text}\")\n",
    "\n",
    "    if news_title:\n",
    "        print(f\"News Title: {news_title.text}\")\n",
    "\n",
    "    if news_link:\n",
    "        print(f\"News Link: {news_link['href']}\")\n",
    "\n",
    "else:\n",
    "    print(\"News row not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179329b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finviz.com/news.ashx'  # Replace this with the actual URL of the website\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "for news_item in news_items:\n",
    "    date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "    title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "    \n",
    "    print(f\"Title: {title}\\nDate Posted: {date_posted}\\n\" & 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b62a6601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dow drops more than 300 points as bank fears grow\n",
      "Date Posted: 10:26AM\n",
      "\n",
      "Title: Zoetis reports weak pet products sales, shares fall\n",
      "Date Posted: 10:24AM\n",
      "\n",
      "Title: US weekly jobless claims rise; labor costs surge as productivity slumps\n",
      "Date Posted: 10:17AM\n",
      "\n",
      "Title: Senator Elizabeth Warren seeks information from First Republic's former CEO - WSJ\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Most Gulf markets in black as oil edges higher\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Regional-Bank Shares Dive as Investors Fret About Contagion\n",
      "Date Posted: 09:50AM\n",
      "\n",
      "Title: Lagarde’s Introductory Remarks at ECB Press Conference: Text\n",
      "Date Posted: 09:44AM\n",
      "\n",
      "Title: U.S. stocks open lower after Fed interest-rate decision, regional banks under renewed pressure\n",
      "Date Posted: 09:39AM\n",
      "\n",
      "Title: Bank Drama Keeps Lid on Stocks With VIX Near 20: Markets Wrap\n",
      "Date Posted: 09:38AM\n",
      "\n",
      "Title: Transcript: Care Work in the United States Has Been Broken for Years\n",
      "Date Posted: 09:32AM\n",
      "\n",
      "Title: 2-year Treasury yield falls below 3.9% day after Fed rate hike, pointing to widening disconnect between markets and central bank\n",
      "Date Posted: 09:25AM\n",
      "\n",
      "Title: Singapore's Moment Is Here. Will It Last?\n",
      "Date Posted: 09:18AM\n",
      "\n",
      "Title: Carl Icahn’s company’s stock slides another 5.6% premarket in wake of short-seller report\n",
      "Date Posted: 09:17AM\n",
      "\n",
      "Title: Jobless claims come in higher than expected ahead of April jobs report\n",
      "Date Posted: 09:13AM\n",
      "\n",
      "Title: Number of people getting mortgages rises sharply\n",
      "Date Posted: 09:12AM\n",
      "\n",
      "Title: Elizabeth Warren Seeks Information From First Republic's Former CEO\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: PacWest, First Horizon Slump, Reigniting Regional Bank Jitters\n",
      "Date Posted: 08:56AM\n",
      "\n",
      "Title: Euro zone bond yields and euro fall after ECB hikes rates\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: Qualcomm amplifies chip gloom with 'sobering report'\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: UK to Censure Tory Donor Rowland and Banque Havilland Over Qatari Plan\n",
      "Date Posted: 08:50AM\n",
      "\n",
      "Title: Watch: ECB President Christine Lagarde speaks after rate decision\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: PacWest plunges as plummeting bank stocks test predictions that worst of crisis is over\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: German Bonds Gain, Euro Slips as ECB Slows Rate Hiking Pace\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: US Jobless Claims Rise Most in Six Weeks, Continuing Claims Fall\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: US Productivity Declines More Than Forecast, Labor Costs Climb\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: Berkshire Die-Hards Flock to Omaha as Market Volatility Reigns\n",
      "Date Posted: 08:32AM\n",
      "\n",
      "Title: European Central Bank Raises Rates Again, but Only a Quarter Point\n",
      "Date Posted: 08:21AM\n",
      "\n",
      "Title: ECB Vows More Hiking to Come After Slowing Tightening Pace\n",
      "Date Posted: 08:20AM\n",
      "\n",
      "Title: Kellogg tops earnings estimates in Q1 and raises guidance\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: Royal Caribbean stock rallies after much narrower-than-expected loss and raised profit outlook, as demand has ‘swiftly’ accelerated\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: BorgWarner sees annual sales below estimates on supply snags, higher costs\n",
      "Date Posted: 08:12AM\n",
      "\n",
      "Title: Kenya Eurobonds Jump After IMF’s Support for ‘Vigorous Action’\n",
      "Date Posted: 08:10AM\n",
      "\n",
      "Title: FDIC enlists BlackRock to clean up banking castoffs\n",
      "Date Posted: 08:09AM\n",
      "\n",
      "Title: PacWest’s Plunge Reignites Fears About America’s Regional Banks\n",
      "Date Posted: 08:04AM\n",
      "\n",
      "Title: Refiners Have a Lot Riding on Summer Driving Season\n",
      "Date Posted: 08:00AM\n",
      "\n",
      "Title: PacWest Says It’s Exploring Options After Shares Plunge\n",
      "Date Posted: 07:56AM\n",
      "\n",
      "Title: Apollo to take aerospace supplier Arconic private in $5.2 bln deal\n",
      "Date Posted: 07:55AM\n",
      "\n",
      "Title: Stocks making the biggest moves before the bell: Paramount, PacWest, Shopify & more\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Shake Shack stock shoots up after burger chain reports a narrower-than-expected loss and a revenue beat\n",
      "Date Posted: 07:45AM\n",
      "\n",
      "Title: Paramount slashes quarterly dividend by 79%, stock plummets\n",
      "Date Posted: 07:44AM\n",
      "\n",
      "Title: Paramount Global revenue disappoints on subscriber loss, weak ad market\n",
      "Date Posted: 07:43AM\n",
      "\n",
      "Title: UAE to Ship Less Oil From This Month in Line With OPEC+ Cuts\n",
      "Date Posted: 07:42AM\n",
      "\n",
      "Title: S.Africa's Pick n Pay warns earnings may fall again if blackouts persist\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: TSX futures inch lower on mixed signals from US Fed\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: Regeneron tops Q1 estimates but lowers margin guidance, sending stock lower\n",
      "Date Posted: 07:36AM\n",
      "\n",
      "Title: Slower sales at debt-laden French retailer Casino sink shares\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Datadog stock advances after earnings beat\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Papa John’s tops profit expectations, but revenue and same-store sales fall short\n",
      "Date Posted: 07:31AM\n",
      "\n",
      "Title: Russian rouble soars to one-month high as oil prices halt slide\n",
      "Date Posted: 07:23AM\n",
      "\n",
      "Title: Regeneron's Eylea drug misses sales estimates as competition heats up\n",
      "Date Posted: 07:19AM\n",
      "\n",
      "Title: Shopify to cut 20% of its workforce, beats quarterly revenue estimates\n",
      "Date Posted: 07:12AM\n",
      "\n",
      "Title: Toronto-Dominion Bank, First Horizon Terminate Merger Agreement\n",
      "Date Posted: 07:08AM\n",
      "\n",
      "Title: IMF to Disburse $300 Million to Kenya After Review Completed\n",
      "Date Posted: 07:07AM\n",
      "\n",
      "Title: China Asks SOEs to Enhance Security Checks When Picking Auditors\n",
      "Date Posted: 07:03AM\n",
      "\n",
      "Title: Here’s when history says the post-Fed rally should start — and the two unlikely sectors to benefit\n",
      "Date Posted: 07:02AM\n",
      "\n",
      "Title: Apollo Agrees to Buy Parts Maker Arconic for About $3 Billion\n",
      "Date Posted: 07:00AM\n",
      "\n",
      "Title: PacWest, Western Alliance hit as US banking concerns widen\n",
      "Date Posted: 06:57AM\n",
      "\n",
      "Title: Canadian lender TD calls off $13.4 bln deal to buy First Horizon Bank\n",
      "Date Posted: 06:53AM\n",
      "\n",
      "Title: Moderna beats COVID vaccine sales expectations as deferred revenue rolls in\n",
      "Date Posted: 06:42AM\n",
      "\n",
      "Title: Futures waver as PacWest slide offsets Fed pause optimism\n",
      "Date Posted: 06:31AM\n",
      "\n",
      "Title: BlackRock, LGIM Pick Europe Credit Over US as Bank Woes Deepen\n",
      "Date Posted: 06:27AM\n",
      "\n",
      "Title: Oil Prices Under Pressure on Economic Fears, Gusher of Russian Supply\n",
      "Date Posted: 06:24AM\n",
      "\n",
      "Title: Spring homebuyers to continue facing inventory woes\n",
      "Date Posted: 06:11AM\n",
      "\n",
      "Title: Adani Flagship Profit Jumps 138% as It Moves Past Hindenburg Hit\n",
      "Date Posted: 06:07AM\n",
      "\n",
      "Title: AMERICAS Hike and hold, bank angst and Apple\n",
      "Date Posted: 06:05AM\n",
      "\n",
      "Title: Shell Reports $9.6 Billion Profit, Despite Falling Oil Prices\n",
      "Date Posted: 06:04AM\n",
      "\n",
      "Title: Africa’s Biggest Fund Manager Boosts Gold Fields Stake to 15%\n",
      "Date Posted: 06:03AM\n",
      "\n",
      "Title: British Gas to stop using contractors to force-fit prepayment meters\n",
      "Date Posted: 06:01AM\n",
      "\n",
      "Title: US bank seeks buyer as confidence crisis spreads\n",
      "Date Posted: 05:46AM\n",
      "\n",
      "Title: Swiss Hit With 120 Lawsuits Over Credit Suisse AT1 Bond Wipeout\n",
      "Date Posted: 05:40AM\n",
      "\n",
      "Title: PacWest tumbles on weighing options, other U.S. regional bank stocks fall\n",
      "Date Posted: 05:33AM\n",
      "\n",
      "Title: Pick n Pay Plunges as It Girds for $55 Million Extra Power Cost\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Warren Buffett Has Been Betting Big on Oil. It's Time to Find Out Why.\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Corporate Profit Margins Are Finally Stabilizing\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: UK Watchdog Aims to Improve Whistleblower Procedures After Backlash\n",
      "Date Posted: 05:23AM\n",
      "\n",
      "Title: PacWest Stock Crumbles Amid Investor Talks\n",
      "Date Posted: 05:07AM\n",
      "\n",
      "Title: The U.K. Economy Needs a Pick-Me-Up. Is the Coronation Enough?\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Why China’s Censors Are Deleting Videos About Poverty\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Even as China Reopens, Security Visits Spook Foreign Businesses\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: White House Unveils Initiatives to Reduce Risks of AI\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Dollar under pressure after Fed, eyes on ECB\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Most Gulf bourses in red after Fed rate hike\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: AIB upgrades guidance after 70% jump in first quarter income\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Hong Kong’s Retail Sales Jump in March as Rebound Strengthens\n",
      "Date Posted: 04:55AM\n",
      "\n",
      "Title: UK's Trainline rises after upbeat FY revenue forecast on travel recovery\n",
      "Date Posted: 04:46AM\n",
      "\n",
      "Title: UK Mortgage Lending Stalls for First Time Since Pandemic in 2021\n",
      "Date Posted: 04:41AM\n",
      "\n",
      "Title: London Stock Exchange CEO Says Execs Should Be Paid More to Boost UK\n",
      "Date Posted: 04:39AM\n",
      "\n",
      "Title: Book profits in Indian equities as U.S. recession imminent - BofA Securities\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: Novo Nordisk cuts some US supply of obesity drug Wegovy to cope with demand\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: A 40% Earnings Downgrade Awaits Indian Stocks, BofA Says\n",
      "Date Posted: 04:31AM\n",
      "\n",
      "Title: White House Rejects Kremlin Statement US \"Undoubtedly\" Behind Drone Attack On Kremlin\n",
      "Date Posted: 10:15AM\n",
      "\n",
      "Title: A \"Pause\" That Does Not Refresh\n",
      "Date Posted: 09:53AM\n",
      "\n",
      "Title: Which Jobs Will Be Most Impacted By ChatGPT?\n",
      "Date Posted: 09:35AM\n",
      "\n",
      "Title: Initial Jobless Claims Jump Near 18 Month High\n",
      "Date Posted: 09:19AM\n",
      "\n",
      "Title: Brace For Rate Impact As Fed Drops Duration Shield\n",
      "Date Posted: 09:15AM\n",
      "\n",
      "Title: /Panic with Friends - Ben Hunt of Epsilon Theory on Rational Optimism and Countering a Coordinated Attack On The Narrative of the United States\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: Russia Says US Behind Overnight Drone Attack On Oil Refinery\n",
      "Date Posted: 08:55AM\n",
      "\n",
      "Title: Market Ignores Fed Chair Powell's Comments, Prices in More Interest Rate Cuts\n",
      "Date Posted: 08:52AM\n",
      "\n",
      "Title: Trade Deficit decreased to $64.2 Billion in March\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: Weekly Initial Unemployment Claims increase to 242,000\n",
      "Date Posted: 08:33AM\n",
      "\n",
      "Title: What If The Fed Has Lost Control?\n",
      "Date Posted: 08:30AM\n",
      "\n",
      "Title: ECB Hikes Rates By 25bps (As Expected), Warns \"Inflation Continues To Be Too High For Too Long\"\n",
      "Date Posted: 08:24AM\n",
      "\n",
      "Title: Futures Slide As Fed Pauses Rate Hikes, Regional Banks Resume Plunge\n",
      "Date Posted: 08:03AM\n",
      "\n",
      "Title: Cloudflare: Bull Case Busted?\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Three Things Traders Are Watching From The ECB Today\n",
      "Date Posted: 07:50AM\n",
      "\n",
      "Title: GMF And EEMA: Risk And Opportunity In Emerging Asian Markets\n",
      "Date Posted: 06:35AM\n",
      "\n",
      "Title: Southwestern Energy: Undervalued Natural Gas Company\n",
      "Date Posted: 06:30AM\n",
      "\n",
      "Title: The Absolute Return Partners May 2023 Letter\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Thursday: Unemployment Claims, Trade Balance\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Losses with distribution as resistance holds for the S&P and Nasdaq\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Embark Technology: Does This Tech Stub Cigar Butt Have One Last Puff?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: The Fed’s Final Rate Hike?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Heavy Truck Sales Up Sharply Year-over-year in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: CVS Health: Explaining The Guidance Cut And How To Evaluate It After Q1 Earnings Beat\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Fed Says Banking System is Sound and Resilient, Hikes Interest Rate a Quarter Point\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: FOMC Statement: Raise Rates 25 bp; Pause in June Likely\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: An 86% Chance of Fed Rate Hike Today and a 12% Chance of a Cut in June\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Wednesday links: calling while you can\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: A Record Low 13 Percent of Eighth Grade Students Are Proficient in History\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Black Knight Mortgage Monitor: Home Prices Increased in March; Prices Up 1.0% YoY\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: HVS: Q1 2023 Homeownership and Vacancy Rates; Rental Vacancy Rates Increased Sharply\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ISM® Services Index Increases to 51.9% in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Personal finance links: the need to impress\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: PacWest Bancorp: The Forest And The Trees\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Ford Soundly Beats Earnings Estimates But Shares Decline Anyway, Why?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ADP: Private Employment Increased 296,000 in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Frienemies ...The Twitter API Wars\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: MBA: Mortgage Applications Decreased in Weekly Survey\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: AGNC: Mortgage Supply/Demand Shifts Will Support The 15% Dividend Yield, Buy\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Leads And Lags: Timing A Recession\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Another Zombie Bites the Dust\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Job Openings Dive But Quits Tell a Better Story of the Weakening Job Market\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Tuesday links: avoiding burnout\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Research links: effective ETF strategies\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Ferrari Could Be Racing Towards An Earnings Beat\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Technology Comes For Everyone and Every Thing\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: How to Trigger a Bank Crash\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: There's a 94 Percent Chance of a Rate Hike on May 3, Then What?\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Narrow action for markets does everthing but breakout\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Rickards: Fed’s Looking in Wrong Direction\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Fed Admits a Mistake in Collapse of SVB, Seeks More Power Anyway\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Monday links: a tortured existence\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Manufacturing ISM Contracts Six Straight  Month, New Orders Down Eight Months\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: An Invite You Cannot Refuse, JPMorgan Takes Over First Republic Bank, Big Get Bigger\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Adviser links: starting small\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Momentum Monday - Is Owning Microsoft, Apple, Nvidia Diversification and The Bull Market In France\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Art of Asking the Right Questions\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Nasdaq and S&P launch another attack at resistance as Russell 2000 struggles.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Sunday links: hours wasted\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Happy Birthday Max Lindzon (24) and Sunday Reads And Listens ...The State of US Venture Capital in 2023.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Top clicks this week on Abnormal Returns\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: We Have Met the Enemy\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: Saturday links: prioritizing fun\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: “Something Clearly Went Wrong”\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Living In The Future Via Tel Aviv\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Friday links: de-risked projects\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: “Your Backhanded Support of Tucker Carlson Is Despicable”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: “You’ll Be Poor and Like It, Beggar!”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Panic with Friends - Oana Manolache, Founder and CEO of Sequel.io, on Empowering Brands with Unique Live Experiences that Connect Customers\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Why We Stand With Tucker Carlson\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: \"Death Cross\" in Russell 2000 as sellers strike markets\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: Good Morning From Tel Aviv...\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: “Kill the Whales!”\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: Goodbye South of France...Can't Wait To Come Back\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: For today, read yesterday - no change in state of play.\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Momentum Monday - The Degenerate Economy Is Gathering Steam\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Neutral finish to week; indices ready to rally.\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Three Best Practices for Making Lasting Life Changes\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Minor losses keep things close to resistance\n",
      "Date Posted: Apr-20\n",
      "\n",
      "Title: Bearish candlesticks on tags of indices resistance\n",
      "Date Posted: Apr-18\n",
      "\n",
      "Title: A tale of two cities; Nasdaq leads, but Russell 2000 in trouble.\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: How to Assess the Personality of the Stock Market\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: What Makes for Success: Five Perspectives From Trading Psychology\n",
      "Date Posted: Apr-09\n",
      "\n",
      "Title: Nasdaq primed for breakout\n",
      "Date Posted: Apr-05\n",
      "\n",
      "Title: Breadth Thrusts in the Stock Market: What Comes Next?\n",
      "Date Posted: Apr-02\n",
      "\n",
      "Title: Understanding Market Themes From Sector Breadth\n",
      "Date Posted: Mar-26\n",
      "\n",
      "Title: Making Passion Your Purpose\n",
      "Date Posted: Mar-19\n",
      "\n",
      "Title: Broad Stock Market Selloff:  What Comes Next?\n",
      "Date Posted: Mar-11\n",
      "\n",
      "Title: The Most Important Factor in Successful Relationships\n",
      "Date Posted: Mar-05\n",
      "\n",
      "Title: New Issue Now Available: What Hedge Funds Bought/Sold in Q1 Volatility\n",
      "Date Posted: May-21\n",
      "\n",
      "The data has been saved to 'news_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finviz.com/news.ashx'  # Replace this with the actual URL of the website\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "    # Create and open the CSV file for writing\n",
    "    with open('news_data_v1.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['Title', 'Date Posted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the CSV header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Iterate over the news items and write each row to the CSV file\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "            print(f\"Title: {title}\\nDate Posted: {date_posted}\\n\")\n",
    "            writer.writerow({'Title': title, 'Date Posted': date_posted})\n",
    "\n",
    "    print(\"The data has been saved to 'news_data.csv'\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dba845ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dow drops more than 300 points, turns negative for the year as bank fears grow\n",
      "Date Posted: 10:30AM\n",
      "\n",
      "Title: Zoetis reports weak pet products sales, shares fall\n",
      "Date Posted: 10:24AM\n",
      "\n",
      "Title: US weekly jobless claims rise; labor costs surge as productivity slumps\n",
      "Date Posted: 10:17AM\n",
      "\n",
      "Title: Senator Elizabeth Warren seeks information from First Republic's former CEO - WSJ\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Most Gulf markets in black as oil edges higher\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Regional-Bank Shares Dive as Investors Fret About Contagion\n",
      "Date Posted: 09:50AM\n",
      "\n",
      "Title: Lagarde’s Introductory Remarks at ECB Press Conference: Text\n",
      "Date Posted: 09:44AM\n",
      "\n",
      "Title: U.S. stocks open lower after Fed interest-rate decision, regional banks under renewed pressure\n",
      "Date Posted: 09:39AM\n",
      "\n",
      "Title: Bank Drama Keeps Lid on Stocks With VIX Near 20: Markets Wrap\n",
      "Date Posted: 09:38AM\n",
      "\n",
      "Title: Transcript: Care Work in the United States Has Been Broken for Years\n",
      "Date Posted: 09:32AM\n",
      "\n",
      "Title: 2-year Treasury yield falls below 3.9% day after Fed rate hike, pointing to widening disconnect between markets and central bank\n",
      "Date Posted: 09:25AM\n",
      "\n",
      "Title: Singapore's Moment Is Here. Will It Last?\n",
      "Date Posted: 09:18AM\n",
      "\n",
      "Title: Carl Icahn’s company’s stock slides another 5.6% premarket in wake of short-seller report\n",
      "Date Posted: 09:17AM\n",
      "\n",
      "Title: Jobless claims come in higher than expected ahead of April jobs report\n",
      "Date Posted: 09:13AM\n",
      "\n",
      "Title: Number of people getting mortgages rises sharply\n",
      "Date Posted: 09:12AM\n",
      "\n",
      "Title: Elizabeth Warren Seeks Information From First Republic's Former CEO\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: PacWest, First Horizon Slump, Reigniting Regional Bank Jitters\n",
      "Date Posted: 08:56AM\n",
      "\n",
      "Title: Euro zone bond yields and euro fall after ECB hikes rates\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: Qualcomm amplifies chip gloom with 'sobering report'\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: UK to Censure Tory Donor Rowland and Banque Havilland Over Qatari Plan\n",
      "Date Posted: 08:50AM\n",
      "\n",
      "Title: Watch: ECB President Christine Lagarde speaks after rate decision\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: PacWest plunges as plummeting bank stocks test predictions that worst of crisis is over\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: German Bonds Gain, Euro Slips as ECB Slows Rate Hiking Pace\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: US Jobless Claims Rise Most in Six Weeks, Continuing Claims Fall\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: US Productivity Declines More Than Forecast, Labor Costs Climb\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: Berkshire Die-Hards Flock to Omaha as Market Volatility Reigns\n",
      "Date Posted: 08:32AM\n",
      "\n",
      "Title: European Central Bank Raises Rates Again, but Only a Quarter Point\n",
      "Date Posted: 08:21AM\n",
      "\n",
      "Title: ECB Vows More Hiking to Come After Slowing Tightening Pace\n",
      "Date Posted: 08:20AM\n",
      "\n",
      "Title: Kellogg tops earnings estimates in Q1 and raises guidance\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: Royal Caribbean stock rallies after much narrower-than-expected loss and raised profit outlook, as demand has ‘swiftly’ accelerated\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: BorgWarner sees annual sales below estimates on supply snags, higher costs\n",
      "Date Posted: 08:12AM\n",
      "\n",
      "Title: Kenya Eurobonds Jump After IMF’s Support for ‘Vigorous Action’\n",
      "Date Posted: 08:10AM\n",
      "\n",
      "Title: FDIC enlists BlackRock to clean up banking castoffs\n",
      "Date Posted: 08:09AM\n",
      "\n",
      "Title: PacWest’s Plunge Reignites Fears About America’s Regional Banks\n",
      "Date Posted: 08:04AM\n",
      "\n",
      "Title: Refiners Have a Lot Riding on Summer Driving Season\n",
      "Date Posted: 08:00AM\n",
      "\n",
      "Title: PacWest Says It’s Exploring Options After Shares Plunge\n",
      "Date Posted: 07:56AM\n",
      "\n",
      "Title: Apollo to take aerospace supplier Arconic private in $5.2 bln deal\n",
      "Date Posted: 07:55AM\n",
      "\n",
      "Title: Stocks making the biggest moves before the bell: Paramount, PacWest, Shopify & more\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Shake Shack stock shoots up after burger chain reports a narrower-than-expected loss and a revenue beat\n",
      "Date Posted: 07:45AM\n",
      "\n",
      "Title: Paramount slashes quarterly dividend by 79%, stock plummets\n",
      "Date Posted: 07:44AM\n",
      "\n",
      "Title: Paramount Global revenue disappoints on subscriber loss, weak ad market\n",
      "Date Posted: 07:43AM\n",
      "\n",
      "Title: UAE to Ship Less Oil From This Month in Line With OPEC+ Cuts\n",
      "Date Posted: 07:42AM\n",
      "\n",
      "Title: S.Africa's Pick n Pay warns earnings may fall again if blackouts persist\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: TSX futures inch lower on mixed signals from US Fed\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: Regeneron tops Q1 estimates but lowers margin guidance, sending stock lower\n",
      "Date Posted: 07:36AM\n",
      "\n",
      "Title: Slower sales at debt-laden French retailer Casino sink shares\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Datadog stock advances after earnings beat\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Papa John’s tops profit expectations, but revenue and same-store sales fall short\n",
      "Date Posted: 07:31AM\n",
      "\n",
      "Title: Russian rouble soars to one-month high as oil prices halt slide\n",
      "Date Posted: 07:23AM\n",
      "\n",
      "Title: Regeneron's Eylea drug misses sales estimates as competition heats up\n",
      "Date Posted: 07:19AM\n",
      "\n",
      "Title: Shopify to cut 20% of its workforce, beats quarterly revenue estimates\n",
      "Date Posted: 07:12AM\n",
      "\n",
      "Title: Toronto-Dominion Bank, First Horizon Terminate Merger Agreement\n",
      "Date Posted: 07:08AM\n",
      "\n",
      "Title: IMF to Disburse $300 Million to Kenya After Review Completed\n",
      "Date Posted: 07:07AM\n",
      "\n",
      "Title: China Asks SOEs to Enhance Security Checks When Picking Auditors\n",
      "Date Posted: 07:03AM\n",
      "\n",
      "Title: Here’s when history says the post-Fed rally should start — and the two unlikely sectors to benefit\n",
      "Date Posted: 07:02AM\n",
      "\n",
      "Title: Apollo Agrees to Buy Parts Maker Arconic for About $3 Billion\n",
      "Date Posted: 07:00AM\n",
      "\n",
      "Title: PacWest, Western Alliance hit as US banking concerns widen\n",
      "Date Posted: 06:57AM\n",
      "\n",
      "Title: Canadian lender TD calls off $13.4 bln deal to buy First Horizon Bank\n",
      "Date Posted: 06:53AM\n",
      "\n",
      "Title: Moderna beats COVID vaccine sales expectations as deferred revenue rolls in\n",
      "Date Posted: 06:42AM\n",
      "\n",
      "Title: Futures waver as PacWest slide offsets Fed pause optimism\n",
      "Date Posted: 06:31AM\n",
      "\n",
      "Title: BlackRock, LGIM Pick Europe Credit Over US as Bank Woes Deepen\n",
      "Date Posted: 06:27AM\n",
      "\n",
      "Title: Oil Prices Under Pressure on Economic Fears, Gusher of Russian Supply\n",
      "Date Posted: 06:24AM\n",
      "\n",
      "Title: Spring homebuyers to continue facing inventory woes\n",
      "Date Posted: 06:11AM\n",
      "\n",
      "Title: Adani Flagship Profit Jumps 138% as It Moves Past Hindenburg Hit\n",
      "Date Posted: 06:07AM\n",
      "\n",
      "Title: AMERICAS Hike and hold, bank angst and Apple\n",
      "Date Posted: 06:05AM\n",
      "\n",
      "Title: Shell Reports $9.6 Billion Profit, Despite Falling Oil Prices\n",
      "Date Posted: 06:04AM\n",
      "\n",
      "Title: Africa’s Biggest Fund Manager Boosts Gold Fields Stake to 15%\n",
      "Date Posted: 06:03AM\n",
      "\n",
      "Title: British Gas to stop using contractors to force-fit prepayment meters\n",
      "Date Posted: 06:01AM\n",
      "\n",
      "Title: US bank seeks buyer as confidence crisis spreads\n",
      "Date Posted: 05:46AM\n",
      "\n",
      "Title: Swiss Hit With 120 Lawsuits Over Credit Suisse AT1 Bond Wipeout\n",
      "Date Posted: 05:40AM\n",
      "\n",
      "Title: PacWest tumbles on weighing options, other U.S. regional bank stocks fall\n",
      "Date Posted: 05:33AM\n",
      "\n",
      "Title: Pick n Pay Plunges as It Girds for $55 Million Extra Power Cost\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Warren Buffett Has Been Betting Big on Oil. It's Time to Find Out Why.\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Corporate Profit Margins Are Finally Stabilizing\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: UK Watchdog Aims to Improve Whistleblower Procedures After Backlash\n",
      "Date Posted: 05:23AM\n",
      "\n",
      "Title: PacWest Stock Crumbles Amid Investor Talks\n",
      "Date Posted: 05:07AM\n",
      "\n",
      "Title: The U.K. Economy Needs a Pick-Me-Up. Is the Coronation Enough?\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Why China’s Censors Are Deleting Videos About Poverty\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Even as China Reopens, Security Visits Spook Foreign Businesses\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: White House Unveils Initiatives to Reduce Risks of AI\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Dollar under pressure after Fed, eyes on ECB\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Most Gulf bourses in red after Fed rate hike\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: AIB upgrades guidance after 70% jump in first quarter income\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Hong Kong’s Retail Sales Jump in March as Rebound Strengthens\n",
      "Date Posted: 04:55AM\n",
      "\n",
      "Title: UK's Trainline rises after upbeat FY revenue forecast on travel recovery\n",
      "Date Posted: 04:46AM\n",
      "\n",
      "Title: UK Mortgage Lending Stalls for First Time Since Pandemic in 2021\n",
      "Date Posted: 04:41AM\n",
      "\n",
      "Title: London Stock Exchange CEO Says Execs Should Be Paid More to Boost UK\n",
      "Date Posted: 04:39AM\n",
      "\n",
      "Title: Book profits in Indian equities as U.S. recession imminent - BofA Securities\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: Novo Nordisk cuts some US supply of obesity drug Wegovy to cope with demand\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: A 40% Earnings Downgrade Awaits Indian Stocks, BofA Says\n",
      "Date Posted: 04:31AM\n",
      "\n",
      "Title: White House Rejects Kremlin Statement US \"Undoubtedly\" Behind Drone Attack On Kremlin\n",
      "Date Posted: 10:15AM\n",
      "\n",
      "Title: A \"Pause\" That Does Not Refresh\n",
      "Date Posted: 09:53AM\n",
      "\n",
      "Title: Which Jobs Will Be Most Impacted By ChatGPT?\n",
      "Date Posted: 09:35AM\n",
      "\n",
      "Title: Initial Jobless Claims Jump Near 18 Month High\n",
      "Date Posted: 09:19AM\n",
      "\n",
      "Title: Brace For Rate Impact As Fed Drops Duration Shield\n",
      "Date Posted: 09:15AM\n",
      "\n",
      "Title: /Panic with Friends - Ben Hunt of Epsilon Theory on Rational Optimism and Countering a Coordinated Attack On The Narrative of the United States\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: Russia Says US Behind Overnight Drone Attack On Oil Refinery\n",
      "Date Posted: 08:55AM\n",
      "\n",
      "Title: Market Ignores Fed Chair Powell's Comments, Prices in More Interest Rate Cuts\n",
      "Date Posted: 08:52AM\n",
      "\n",
      "Title: Trade Deficit decreased to $64.2 Billion in March\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: Weekly Initial Unemployment Claims increase to 242,000\n",
      "Date Posted: 08:33AM\n",
      "\n",
      "Title: What If The Fed Has Lost Control?\n",
      "Date Posted: 08:30AM\n",
      "\n",
      "Title: ECB Hikes Rates By 25bps (As Expected), Warns \"Inflation Continues To Be Too High For Too Long\"\n",
      "Date Posted: 08:24AM\n",
      "\n",
      "Title: Futures Slide As Fed Pauses Rate Hikes, Regional Banks Resume Plunge\n",
      "Date Posted: 08:03AM\n",
      "\n",
      "Title: Cloudflare: Bull Case Busted?\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Three Things Traders Are Watching From The ECB Today\n",
      "Date Posted: 07:50AM\n",
      "\n",
      "Title: GMF And EEMA: Risk And Opportunity In Emerging Asian Markets\n",
      "Date Posted: 06:35AM\n",
      "\n",
      "Title: Southwestern Energy: Undervalued Natural Gas Company\n",
      "Date Posted: 06:30AM\n",
      "\n",
      "Title: The Absolute Return Partners May 2023 Letter\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Thursday: Unemployment Claims, Trade Balance\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Losses with distribution as resistance holds for the S&P and Nasdaq\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Embark Technology: Does This Tech Stub Cigar Butt Have One Last Puff?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: The Fed’s Final Rate Hike?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Heavy Truck Sales Up Sharply Year-over-year in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: CVS Health: Explaining The Guidance Cut And How To Evaluate It After Q1 Earnings Beat\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Fed Says Banking System is Sound and Resilient, Hikes Interest Rate a Quarter Point\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: FOMC Statement: Raise Rates 25 bp; Pause in June Likely\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: An 86% Chance of Fed Rate Hike Today and a 12% Chance of a Cut in June\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Wednesday links: calling while you can\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: A Record Low 13 Percent of Eighth Grade Students Are Proficient in History\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Black Knight Mortgage Monitor: Home Prices Increased in March; Prices Up 1.0% YoY\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: HVS: Q1 2023 Homeownership and Vacancy Rates; Rental Vacancy Rates Increased Sharply\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ISM® Services Index Increases to 51.9% in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Personal finance links: the need to impress\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: PacWest Bancorp: The Forest And The Trees\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Ford Soundly Beats Earnings Estimates But Shares Decline Anyway, Why?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ADP: Private Employment Increased 296,000 in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Frienemies ...The Twitter API Wars\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: MBA: Mortgage Applications Decreased in Weekly Survey\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: AGNC: Mortgage Supply/Demand Shifts Will Support The 15% Dividend Yield, Buy\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Leads And Lags: Timing A Recession\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Another Zombie Bites the Dust\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Job Openings Dive But Quits Tell a Better Story of the Weakening Job Market\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Tuesday links: avoiding burnout\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Research links: effective ETF strategies\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Ferrari Could Be Racing Towards An Earnings Beat\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Technology Comes For Everyone and Every Thing\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: How to Trigger a Bank Crash\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: There's a 94 Percent Chance of a Rate Hike on May 3, Then What?\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Narrow action for markets does everthing but breakout\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Rickards: Fed’s Looking in Wrong Direction\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Fed Admits a Mistake in Collapse of SVB, Seeks More Power Anyway\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Monday links: a tortured existence\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Manufacturing ISM Contracts Six Straight  Month, New Orders Down Eight Months\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: An Invite You Cannot Refuse, JPMorgan Takes Over First Republic Bank, Big Get Bigger\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Adviser links: starting small\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Momentum Monday - Is Owning Microsoft, Apple, Nvidia Diversification and The Bull Market In France\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Art of Asking the Right Questions\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Nasdaq and S&P launch another attack at resistance as Russell 2000 struggles.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Sunday links: hours wasted\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Happy Birthday Max Lindzon (24) and Sunday Reads And Listens ...The State of US Venture Capital in 2023.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Top clicks this week on Abnormal Returns\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: We Have Met the Enemy\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: Saturday links: prioritizing fun\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: “Something Clearly Went Wrong”\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Living In The Future Via Tel Aviv\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Friday links: de-risked projects\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: “Your Backhanded Support of Tucker Carlson Is Despicable”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: “You’ll Be Poor and Like It, Beggar!”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Panic with Friends - Oana Manolache, Founder and CEO of Sequel.io, on Empowering Brands with Unique Live Experiences that Connect Customers\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Why We Stand With Tucker Carlson\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: \"Death Cross\" in Russell 2000 as sellers strike markets\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: Good Morning From Tel Aviv...\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: “Kill the Whales!”\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: Goodbye South of France...Can't Wait To Come Back\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: For today, read yesterday - no change in state of play.\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Momentum Monday - The Degenerate Economy Is Gathering Steam\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Neutral finish to week; indices ready to rally.\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Three Best Practices for Making Lasting Life Changes\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Minor losses keep things close to resistance\n",
      "Date Posted: Apr-20\n",
      "\n",
      "Title: Bearish candlesticks on tags of indices resistance\n",
      "Date Posted: Apr-18\n",
      "\n",
      "Title: A tale of two cities; Nasdaq leads, but Russell 2000 in trouble.\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: How to Assess the Personality of the Stock Market\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: What Makes for Success: Five Perspectives From Trading Psychology\n",
      "Date Posted: Apr-09\n",
      "\n",
      "Title: Nasdaq primed for breakout\n",
      "Date Posted: Apr-05\n",
      "\n",
      "Title: Breadth Thrusts in the Stock Market: What Comes Next?\n",
      "Date Posted: Apr-02\n",
      "\n",
      "Title: Understanding Market Themes From Sector Breadth\n",
      "Date Posted: Mar-26\n",
      "\n",
      "Title: Making Passion Your Purpose\n",
      "Date Posted: Mar-19\n",
      "\n",
      "Title: Broad Stock Market Selloff:  What Comes Next?\n",
      "Date Posted: Mar-11\n",
      "\n",
      "Title: The Most Important Factor in Successful Relationships\n",
      "Date Posted: Mar-05\n",
      "\n",
      "Title: New Issue Now Available: What Hedge Funds Bought/Sold in Q1 Volatility\n",
      "Date Posted: May-21\n",
      "\n",
      "The data has been saved to 'news_data_v1.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "url = 'https://finviz.com/news.ashx'  # Replace this with the actual URL of the website\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "    # Create and open the CSV file for writing\n",
    "    with open('news_data_v1.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['Title', 'Date Posted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the CSV header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Iterate over the news items and write each row to the CSV file\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            # Check if the date_posted is a valid date\n",
    "            try:\n",
    "                parser.parse(date_posted)\n",
    "            except ValueError:\n",
    "                # If not, use today's date\n",
    "                date_posted = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "            print(f\"Title: {title}\\nDate Posted: {date_posted}\\n\")\n",
    "            writer.writerow({'Title': title, 'Date Posted': date_posted})\n",
    "\n",
    "    print(\"The data has been saved to 'news_data_v1.csv'\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9bd5436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bank Woes Hit Stocks With Few Signs Drama Is Over: Markets Wrap\n",
      "Date Posted: 10:35AM\n",
      "\n",
      "Title: Canada's Ivey PMI shows activity expanding at slower pace in April\n",
      "Date Posted: 10:34AM\n",
      "\n",
      "Title: Dow drops more than 300 points, turns negative for the year as bank fears grow\n",
      "Date Posted: 10:30AM\n",
      "\n",
      "Title: Zoetis reports weak pet products sales, shares fall\n",
      "Date Posted: 10:24AM\n",
      "\n",
      "Title: US weekly jobless claims rise; labor costs surge as productivity slumps\n",
      "Date Posted: 10:17AM\n",
      "\n",
      "Title: Senator Elizabeth Warren seeks information from First Republic's former CEO - WSJ\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Most Gulf markets in black as oil edges higher\n",
      "Date Posted: 09:52AM\n",
      "\n",
      "Title: Regional-Bank Shares Dive as Investors Fret About Contagion\n",
      "Date Posted: 09:50AM\n",
      "\n",
      "Title: Lagarde’s Introductory Remarks at ECB Press Conference: Text\n",
      "Date Posted: 09:44AM\n",
      "\n",
      "Title: U.S. stocks open lower after Fed interest-rate decision, regional banks under renewed pressure\n",
      "Date Posted: 09:39AM\n",
      "\n",
      "Title: Transcript: Care Work in the United States Has Been Broken for Years\n",
      "Date Posted: 09:32AM\n",
      "\n",
      "Title: 2-year Treasury yield falls below 3.9% day after Fed rate hike, pointing to widening disconnect between markets and central bank\n",
      "Date Posted: 09:25AM\n",
      "\n",
      "Title: Singapore's Moment Is Here. Will It Last?\n",
      "Date Posted: 09:18AM\n",
      "\n",
      "Title: Carl Icahn’s company’s stock slides another 5.6% premarket in wake of short-seller report\n",
      "Date Posted: 09:17AM\n",
      "\n",
      "Title: Jobless claims come in higher than expected ahead of April jobs report\n",
      "Date Posted: 09:13AM\n",
      "\n",
      "Title: Number of people getting mortgages rises sharply\n",
      "Date Posted: 09:12AM\n",
      "\n",
      "Title: Elizabeth Warren Seeks Information From First Republic's Former CEO\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: PacWest, First Horizon Slump, Reigniting Regional Bank Jitters\n",
      "Date Posted: 08:56AM\n",
      "\n",
      "Title: Euro zone bond yields and euro fall after ECB hikes rates\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: Qualcomm amplifies chip gloom with 'sobering report'\n",
      "Date Posted: 08:54AM\n",
      "\n",
      "Title: UK to Censure Tory Donor Rowland and Banque Havilland Over Qatari Plan\n",
      "Date Posted: 08:50AM\n",
      "\n",
      "Title: Watch: ECB President Christine Lagarde speaks after rate decision\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: PacWest plunges as plummeting bank stocks test predictions that worst of crisis is over\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: German Bonds Gain, Euro Slips as ECB Slows Rate Hiking Pace\n",
      "Date Posted: 08:43AM\n",
      "\n",
      "Title: US Jobless Claims Rise Most in Six Weeks, Continuing Claims Fall\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: US Productivity Declines More Than Forecast, Labor Costs Climb\n",
      "Date Posted: 08:34AM\n",
      "\n",
      "Title: Berkshire Die-Hards Flock to Omaha as Market Volatility Reigns\n",
      "Date Posted: 08:32AM\n",
      "\n",
      "Title: European Central Bank Raises Rates Again, but Only a Quarter Point\n",
      "Date Posted: 08:21AM\n",
      "\n",
      "Title: ECB Vows More Hiking to Come After Slowing Tightening Pace\n",
      "Date Posted: 08:20AM\n",
      "\n",
      "Title: Kellogg tops earnings estimates in Q1 and raises guidance\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: Royal Caribbean stock rallies after much narrower-than-expected loss and raised profit outlook, as demand has ‘swiftly’ accelerated\n",
      "Date Posted: 08:18AM\n",
      "\n",
      "Title: BorgWarner sees annual sales below estimates on supply snags, higher costs\n",
      "Date Posted: 08:12AM\n",
      "\n",
      "Title: Kenya Eurobonds Jump After IMF’s Support for ‘Vigorous Action’\n",
      "Date Posted: 08:10AM\n",
      "\n",
      "Title: FDIC enlists BlackRock to clean up banking castoffs\n",
      "Date Posted: 08:09AM\n",
      "\n",
      "Title: PacWest’s Plunge Reignites Fears About America’s Regional Banks\n",
      "Date Posted: 08:04AM\n",
      "\n",
      "Title: Refiners Have a Lot Riding on Summer Driving Season\n",
      "Date Posted: 08:00AM\n",
      "\n",
      "Title: PacWest Says It’s Exploring Options After Shares Plunge\n",
      "Date Posted: 07:56AM\n",
      "\n",
      "Title: Apollo to take aerospace supplier Arconic private in $5.2 bln deal\n",
      "Date Posted: 07:55AM\n",
      "\n",
      "Title: Stocks making the biggest moves before the bell: Paramount, PacWest, Shopify & more\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Shake Shack stock shoots up after burger chain reports a narrower-than-expected loss and a revenue beat\n",
      "Date Posted: 07:45AM\n",
      "\n",
      "Title: Paramount slashes quarterly dividend by 79%, stock plummets\n",
      "Date Posted: 07:44AM\n",
      "\n",
      "Title: Paramount Global revenue disappoints on subscriber loss, weak ad market\n",
      "Date Posted: 07:43AM\n",
      "\n",
      "Title: UAE to Ship Less Oil From This Month in Line With OPEC+ Cuts\n",
      "Date Posted: 07:42AM\n",
      "\n",
      "Title: S.Africa's Pick n Pay warns earnings may fall again if blackouts persist\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: TSX futures inch lower on mixed signals from US Fed\n",
      "Date Posted: 07:39AM\n",
      "\n",
      "Title: Regeneron tops Q1 estimates but lowers margin guidance, sending stock lower\n",
      "Date Posted: 07:36AM\n",
      "\n",
      "Title: Slower sales at debt-laden French retailer Casino sink shares\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Datadog stock advances after earnings beat\n",
      "Date Posted: 07:34AM\n",
      "\n",
      "Title: Papa John’s tops profit expectations, but revenue and same-store sales fall short\n",
      "Date Posted: 07:31AM\n",
      "\n",
      "Title: Russian rouble soars to one-month high as oil prices halt slide\n",
      "Date Posted: 07:23AM\n",
      "\n",
      "Title: Regeneron's Eylea drug misses sales estimates as competition heats up\n",
      "Date Posted: 07:19AM\n",
      "\n",
      "Title: Shopify to cut 20% of its workforce, beats quarterly revenue estimates\n",
      "Date Posted: 07:12AM\n",
      "\n",
      "Title: Toronto-Dominion Bank, First Horizon Terminate Merger Agreement\n",
      "Date Posted: 07:08AM\n",
      "\n",
      "Title: IMF to Disburse $300 Million to Kenya After Review Completed\n",
      "Date Posted: 07:07AM\n",
      "\n",
      "Title: China Asks SOEs to Enhance Security Checks When Picking Auditors\n",
      "Date Posted: 07:03AM\n",
      "\n",
      "Title: Here’s when history says the post-Fed rally should start — and the two unlikely sectors to benefit\n",
      "Date Posted: 07:02AM\n",
      "\n",
      "Title: Apollo Agrees to Buy Parts Maker Arconic for About $3 Billion\n",
      "Date Posted: 07:00AM\n",
      "\n",
      "Title: PacWest, Western Alliance hit as US banking concerns widen\n",
      "Date Posted: 06:57AM\n",
      "\n",
      "Title: Canadian lender TD calls off $13.4 bln deal to buy First Horizon Bank\n",
      "Date Posted: 06:53AM\n",
      "\n",
      "Title: Moderna beats COVID vaccine sales expectations as deferred revenue rolls in\n",
      "Date Posted: 06:42AM\n",
      "\n",
      "Title: Futures waver as PacWest slide offsets Fed pause optimism\n",
      "Date Posted: 06:31AM\n",
      "\n",
      "Title: BlackRock, LGIM Pick Europe Credit Over US as Bank Woes Deepen\n",
      "Date Posted: 06:27AM\n",
      "\n",
      "Title: Oil Prices Under Pressure on Economic Fears, Gusher of Russian Supply\n",
      "Date Posted: 06:24AM\n",
      "\n",
      "Title: Spring homebuyers to continue facing inventory woes\n",
      "Date Posted: 06:11AM\n",
      "\n",
      "Title: Adani Flagship Profit Jumps 138% as It Moves Past Hindenburg Hit\n",
      "Date Posted: 06:07AM\n",
      "\n",
      "Title: AMERICAS Hike and hold, bank angst and Apple\n",
      "Date Posted: 06:05AM\n",
      "\n",
      "Title: Shell Reports $9.6 Billion Profit, Despite Falling Oil Prices\n",
      "Date Posted: 06:04AM\n",
      "\n",
      "Title: Africa’s Biggest Fund Manager Boosts Gold Fields Stake to 15%\n",
      "Date Posted: 06:03AM\n",
      "\n",
      "Title: British Gas to stop using contractors to force-fit prepayment meters\n",
      "Date Posted: 06:01AM\n",
      "\n",
      "Title: US bank seeks buyer as confidence crisis spreads\n",
      "Date Posted: 05:46AM\n",
      "\n",
      "Title: Swiss Hit With 120 Lawsuits Over Credit Suisse AT1 Bond Wipeout\n",
      "Date Posted: 05:40AM\n",
      "\n",
      "Title: PacWest tumbles on weighing options, other U.S. regional bank stocks fall\n",
      "Date Posted: 05:33AM\n",
      "\n",
      "Title: Pick n Pay Plunges as It Girds for $55 Million Extra Power Cost\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Warren Buffett Has Been Betting Big on Oil. It's Time to Find Out Why.\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: Corporate Profit Margins Are Finally Stabilizing\n",
      "Date Posted: 05:30AM\n",
      "\n",
      "Title: UK Watchdog Aims to Improve Whistleblower Procedures After Backlash\n",
      "Date Posted: 05:23AM\n",
      "\n",
      "Title: PacWest Stock Crumbles Amid Investor Talks\n",
      "Date Posted: 05:07AM\n",
      "\n",
      "Title: The U.K. Economy Needs a Pick-Me-Up. Is the Coronation Enough?\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Why China’s Censors Are Deleting Videos About Poverty\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Even as China Reopens, Security Visits Spook Foreign Businesses\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: White House Unveils Initiatives to Reduce Risks of AI\n",
      "Date Posted: 05:00AM\n",
      "\n",
      "Title: Dollar under pressure after Fed, eyes on ECB\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Most Gulf bourses in red after Fed rate hike\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: AIB upgrades guidance after 70% jump in first quarter income\n",
      "Date Posted: 04:57AM\n",
      "\n",
      "Title: Hong Kong’s Retail Sales Jump in March as Rebound Strengthens\n",
      "Date Posted: 04:55AM\n",
      "\n",
      "Title: UK's Trainline rises after upbeat FY revenue forecast on travel recovery\n",
      "Date Posted: 04:46AM\n",
      "\n",
      "Title: UK Mortgage Lending Stalls for First Time Since Pandemic in 2021\n",
      "Date Posted: 04:41AM\n",
      "\n",
      "Title: London Stock Exchange CEO Says Execs Should Be Paid More to Boost UK\n",
      "Date Posted: 04:39AM\n",
      "\n",
      "Title: Book profits in Indian equities as U.S. recession imminent - BofA Securities\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: Novo Nordisk cuts some US supply of obesity drug Wegovy to cope with demand\n",
      "Date Posted: 04:37AM\n",
      "\n",
      "Title: White House Rejects Kremlin Statement US \"Undoubtedly\" Behind Drone Attack On Kremlin\n",
      "Date Posted: 10:15AM\n",
      "\n",
      "Title: A \"Pause\" That Does Not Refresh\n",
      "Date Posted: 09:53AM\n",
      "\n",
      "Title: Which Jobs Will Be Most Impacted By ChatGPT?\n",
      "Date Posted: 09:35AM\n",
      "\n",
      "Title: Initial Jobless Claims Jump Near 18 Month High\n",
      "Date Posted: 09:19AM\n",
      "\n",
      "Title: Brace For Rate Impact As Fed Drops Duration Shield\n",
      "Date Posted: 09:15AM\n",
      "\n",
      "Title: /Panic with Friends - Ben Hunt of Epsilon Theory on Rational Optimism and Countering a Coordinated Attack On The Narrative of the United States\n",
      "Date Posted: 09:00AM\n",
      "\n",
      "Title: Russia Says US Behind Overnight Drone Attack On Oil Refinery\n",
      "Date Posted: 08:55AM\n",
      "\n",
      "Title: Market Ignores Fed Chair Powell's Comments, Prices in More Interest Rate Cuts\n",
      "Date Posted: 08:52AM\n",
      "\n",
      "Title: Trade Deficit decreased to $64.2 Billion in March\n",
      "Date Posted: 08:49AM\n",
      "\n",
      "Title: Weekly Initial Unemployment Claims increase to 242,000\n",
      "Date Posted: 08:33AM\n",
      "\n",
      "Title: What If The Fed Has Lost Control?\n",
      "Date Posted: 08:30AM\n",
      "\n",
      "Title: ECB Hikes Rates By 25bps (As Expected), Warns \"Inflation Continues To Be Too High For Too Long\"\n",
      "Date Posted: 08:24AM\n",
      "\n",
      "Title: Futures Slide As Fed Pauses Rate Hikes, Regional Banks Resume Plunge\n",
      "Date Posted: 08:03AM\n",
      "\n",
      "Title: Cloudflare: Bull Case Busted?\n",
      "Date Posted: 07:52AM\n",
      "\n",
      "Title: Three Things Traders Are Watching From The ECB Today\n",
      "Date Posted: 07:50AM\n",
      "\n",
      "Title: GMF And EEMA: Risk And Opportunity In Emerging Asian Markets\n",
      "Date Posted: 06:35AM\n",
      "\n",
      "Title: Southwestern Energy: Undervalued Natural Gas Company\n",
      "Date Posted: 06:30AM\n",
      "\n",
      "Title: The Absolute Return Partners May 2023 Letter\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Thursday: Unemployment Claims, Trade Balance\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Losses with distribution as resistance holds for the S&P and Nasdaq\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Embark Technology: Does This Tech Stub Cigar Butt Have One Last Puff?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: The Fed’s Final Rate Hike?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Heavy Truck Sales Up Sharply Year-over-year in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: CVS Health: Explaining The Guidance Cut And How To Evaluate It After Q1 Earnings Beat\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Fed Says Banking System is Sound and Resilient, Hikes Interest Rate a Quarter Point\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: FOMC Statement: Raise Rates 25 bp; Pause in June Likely\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: An 86% Chance of Fed Rate Hike Today and a 12% Chance of a Cut in June\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Wednesday links: calling while you can\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: A Record Low 13 Percent of Eighth Grade Students Are Proficient in History\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Black Knight Mortgage Monitor: Home Prices Increased in March; Prices Up 1.0% YoY\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: HVS: Q1 2023 Homeownership and Vacancy Rates; Rental Vacancy Rates Increased Sharply\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ISM® Services Index Increases to 51.9% in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Personal finance links: the need to impress\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: PacWest Bancorp: The Forest And The Trees\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Ford Soundly Beats Earnings Estimates But Shares Decline Anyway, Why?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ADP: Private Employment Increased 296,000 in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Frienemies ...The Twitter API Wars\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: MBA: Mortgage Applications Decreased in Weekly Survey\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: AGNC: Mortgage Supply/Demand Shifts Will Support The 15% Dividend Yield, Buy\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Leads And Lags: Timing A Recession\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Another Zombie Bites the Dust\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Job Openings Dive But Quits Tell a Better Story of the Weakening Job Market\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Tuesday links: avoiding burnout\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Research links: effective ETF strategies\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Ferrari Could Be Racing Towards An Earnings Beat\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Technology Comes For Everyone and Every Thing\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: How to Trigger a Bank Crash\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: There's a 94 Percent Chance of a Rate Hike on May 3, Then What?\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Narrow action for markets does everthing but breakout\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Rickards: Fed’s Looking in Wrong Direction\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Fed Admits a Mistake in Collapse of SVB, Seeks More Power Anyway\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Monday links: a tortured existence\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Manufacturing ISM Contracts Six Straight  Month, New Orders Down Eight Months\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: An Invite You Cannot Refuse, JPMorgan Takes Over First Republic Bank, Big Get Bigger\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Adviser links: starting small\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Momentum Monday - Is Owning Microsoft, Apple, Nvidia Diversification and The Bull Market In France\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Art of Asking the Right Questions\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Nasdaq and S&P launch another attack at resistance as Russell 2000 struggles.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Sunday links: hours wasted\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Happy Birthday Max Lindzon (24) and Sunday Reads And Listens ...The State of US Venture Capital in 2023.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Top clicks this week on Abnormal Returns\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: We Have Met the Enemy\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: Saturday links: prioritizing fun\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: “Something Clearly Went Wrong”\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Living In The Future Via Tel Aviv\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Friday links: de-risked projects\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: “Your Backhanded Support of Tucker Carlson Is Despicable”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: “You’ll Be Poor and Like It, Beggar!”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Panic with Friends - Oana Manolache, Founder and CEO of Sequel.io, on Empowering Brands with Unique Live Experiences that Connect Customers\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Why We Stand With Tucker Carlson\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: \"Death Cross\" in Russell 2000 as sellers strike markets\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: Good Morning From Tel Aviv...\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: “Kill the Whales!”\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: Goodbye South of France...Can't Wait To Come Back\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: For today, read yesterday - no change in state of play.\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Momentum Monday - The Degenerate Economy Is Gathering Steam\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Neutral finish to week; indices ready to rally.\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Three Best Practices for Making Lasting Life Changes\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Minor losses keep things close to resistance\n",
      "Date Posted: Apr-20\n",
      "\n",
      "Title: Bearish candlesticks on tags of indices resistance\n",
      "Date Posted: Apr-18\n",
      "\n",
      "Title: A tale of two cities; Nasdaq leads, but Russell 2000 in trouble.\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: How to Assess the Personality of the Stock Market\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: What Makes for Success: Five Perspectives From Trading Psychology\n",
      "Date Posted: Apr-09\n",
      "\n",
      "Title: Nasdaq primed for breakout\n",
      "Date Posted: Apr-05\n",
      "\n",
      "Title: Breadth Thrusts in the Stock Market: What Comes Next?\n",
      "Date Posted: Apr-02\n",
      "\n",
      "Title: Understanding Market Themes From Sector Breadth\n",
      "Date Posted: Mar-26\n",
      "\n",
      "Title: Making Passion Your Purpose\n",
      "Date Posted: Mar-19\n",
      "\n",
      "Title: Broad Stock Market Selloff:  What Comes Next?\n",
      "Date Posted: Mar-11\n",
      "\n",
      "Title: The Most Important Factor in Successful Relationships\n",
      "Date Posted: Mar-05\n",
      "\n",
      "Title: New Issue Now Available: What Hedge Funds Bought/Sold in Q1 Volatility\n",
      "Date Posted: May-21\n",
      "\n",
      "The data has been saved to 'news_data_v1.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "url = 'https://finviz.com/news.ashx'  # Replace this with the actual URL of the website\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "    # Create and open the CSV file for writing\n",
    "    with open('news_data_v1.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['Title', 'Date Posted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the CSV header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Iterate over the news items and write each row to the CSV file\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            # Check if the date_posted is a valid date\n",
    "            try:\n",
    "                parser.parse(date_posted, fuzzy=True)\n",
    "            except ValueError:\n",
    "                # If not, concatenate the time with today's date\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            print(f\"Title: {title}\\nDate Posted: {date_posted}\\n\")\n",
    "            writer.writerow({'Title': title, 'Date Posted': date_posted})\n",
    "\n",
    "    print(\"The data has been saved to 'news_data_v1.csv'\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a985029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Bank Woes Hit Stocks With Few Signs Drama Is Over: Markets Wrap\n",
      "Date Posted: 2023-05-04 10:35AM\n",
      "\n",
      "Title: Canada's Ivey PMI shows activity expanding at slower pace in April\n",
      "Date Posted: 2023-05-04 10:34AM\n",
      "\n",
      "Title: Dow drops more than 300 points, turns negative for the year as bank fears grow\n",
      "Date Posted: 2023-05-04 10:30AM\n",
      "\n",
      "Title: Zoetis reports weak pet products sales, shares fall\n",
      "Date Posted: 2023-05-04 10:24AM\n",
      "\n",
      "Title: US weekly jobless claims rise; labor costs surge as productivity slumps\n",
      "Date Posted: 2023-05-04 10:17AM\n",
      "\n",
      "Title: Senator Elizabeth Warren seeks information from First Republic's former CEO - WSJ\n",
      "Date Posted: 2023-05-04 09:52AM\n",
      "\n",
      "Title: Most Gulf markets in black as oil edges higher\n",
      "Date Posted: 2023-05-04 09:52AM\n",
      "\n",
      "Title: Regional-Bank Shares Dive as Investors Fret About Contagion\n",
      "Date Posted: 2023-05-04 09:50AM\n",
      "\n",
      "Title: Lagarde’s Introductory Remarks at ECB Press Conference: Text\n",
      "Date Posted: 2023-05-04 09:44AM\n",
      "\n",
      "Title: U.S. stocks open lower after Fed interest-rate decision, regional banks under renewed pressure\n",
      "Date Posted: 2023-05-04 09:39AM\n",
      "\n",
      "Title: Transcript: Care Work in the United States Has Been Broken for Years\n",
      "Date Posted: 2023-05-04 09:32AM\n",
      "\n",
      "Title: 2-year Treasury yield falls below 3.9% day after Fed rate hike, pointing to widening disconnect between markets and central bank\n",
      "Date Posted: 2023-05-04 09:25AM\n",
      "\n",
      "Title: Singapore's Moment Is Here. Will It Last?\n",
      "Date Posted: 2023-05-04 09:18AM\n",
      "\n",
      "Title: Carl Icahn’s company’s stock slides another 5.6% premarket in wake of short-seller report\n",
      "Date Posted: 2023-05-04 09:17AM\n",
      "\n",
      "Title: Jobless claims come in higher than expected ahead of April jobs report\n",
      "Date Posted: 2023-05-04 09:13AM\n",
      "\n",
      "Title: Number of people getting mortgages rises sharply\n",
      "Date Posted: 2023-05-04 09:12AM\n",
      "\n",
      "Title: Elizabeth Warren Seeks Information From First Republic's Former CEO\n",
      "Date Posted: 2023-05-04 09:00AM\n",
      "\n",
      "Title: PacWest, First Horizon Slump, Reigniting Regional Bank Jitters\n",
      "Date Posted: 2023-05-04 08:56AM\n",
      "\n",
      "Title: Euro zone bond yields and euro fall after ECB hikes rates\n",
      "Date Posted: 2023-05-04 08:54AM\n",
      "\n",
      "Title: Qualcomm amplifies chip gloom with 'sobering report'\n",
      "Date Posted: 2023-05-04 08:54AM\n",
      "\n",
      "Title: UK to Censure Tory Donor Rowland and Banque Havilland Over Qatari Plan\n",
      "Date Posted: 2023-05-04 08:50AM\n",
      "\n",
      "Title: Watch: ECB President Christine Lagarde speaks after rate decision\n",
      "Date Posted: 2023-05-04 08:49AM\n",
      "\n",
      "Title: PacWest plunges as plummeting bank stocks test predictions that worst of crisis is over\n",
      "Date Posted: 2023-05-04 08:43AM\n",
      "\n",
      "Title: German Bonds Gain, Euro Slips as ECB Slows Rate Hiking Pace\n",
      "Date Posted: 2023-05-04 08:43AM\n",
      "\n",
      "Title: US Jobless Claims Rise Most in Six Weeks, Continuing Claims Fall\n",
      "Date Posted: 2023-05-04 08:34AM\n",
      "\n",
      "Title: US Productivity Declines More Than Forecast, Labor Costs Climb\n",
      "Date Posted: 2023-05-04 08:34AM\n",
      "\n",
      "Title: Berkshire Die-Hards Flock to Omaha as Market Volatility Reigns\n",
      "Date Posted: 2023-05-04 08:32AM\n",
      "\n",
      "Title: European Central Bank Raises Rates Again, but Only a Quarter Point\n",
      "Date Posted: 2023-05-04 08:21AM\n",
      "\n",
      "Title: ECB Vows More Hiking to Come After Slowing Tightening Pace\n",
      "Date Posted: 2023-05-04 08:20AM\n",
      "\n",
      "Title: Kellogg tops earnings estimates in Q1 and raises guidance\n",
      "Date Posted: 2023-05-04 08:18AM\n",
      "\n",
      "Title: Royal Caribbean stock rallies after much narrower-than-expected loss and raised profit outlook, as demand has ‘swiftly’ accelerated\n",
      "Date Posted: 2023-05-04 08:18AM\n",
      "\n",
      "Title: BorgWarner sees annual sales below estimates on supply snags, higher costs\n",
      "Date Posted: 2023-05-04 08:12AM\n",
      "\n",
      "Title: Kenya Eurobonds Jump After IMF’s Support for ‘Vigorous Action’\n",
      "Date Posted: 2023-05-04 08:10AM\n",
      "\n",
      "Title: FDIC enlists BlackRock to clean up banking castoffs\n",
      "Date Posted: 2023-05-04 08:09AM\n",
      "\n",
      "Title: PacWest’s Plunge Reignites Fears About America’s Regional Banks\n",
      "Date Posted: 2023-05-04 08:04AM\n",
      "\n",
      "Title: Refiners Have a Lot Riding on Summer Driving Season\n",
      "Date Posted: 2023-05-04 08:00AM\n",
      "\n",
      "Title: PacWest Says It’s Exploring Options After Shares Plunge\n",
      "Date Posted: 2023-05-04 07:56AM\n",
      "\n",
      "Title: Apollo to take aerospace supplier Arconic private in $5.2 bln deal\n",
      "Date Posted: 2023-05-04 07:55AM\n",
      "\n",
      "Title: Stocks making the biggest moves before the bell: Paramount, PacWest, Shopify & more\n",
      "Date Posted: 2023-05-04 07:52AM\n",
      "\n",
      "Title: Shake Shack stock shoots up after burger chain reports a narrower-than-expected loss and a revenue beat\n",
      "Date Posted: 2023-05-04 07:45AM\n",
      "\n",
      "Title: Paramount slashes quarterly dividend by 79%, stock plummets\n",
      "Date Posted: 2023-05-04 07:44AM\n",
      "\n",
      "Title: Paramount Global revenue disappoints on subscriber loss, weak ad market\n",
      "Date Posted: 2023-05-04 07:43AM\n",
      "\n",
      "Title: UAE to Ship Less Oil From This Month in Line With OPEC+ Cuts\n",
      "Date Posted: 2023-05-04 07:42AM\n",
      "\n",
      "Title: S.Africa's Pick n Pay warns earnings may fall again if blackouts persist\n",
      "Date Posted: 2023-05-04 07:39AM\n",
      "\n",
      "Title: TSX futures inch lower on mixed signals from US Fed\n",
      "Date Posted: 2023-05-04 07:39AM\n",
      "\n",
      "Title: Regeneron tops Q1 estimates but lowers margin guidance, sending stock lower\n",
      "Date Posted: 2023-05-04 07:36AM\n",
      "\n",
      "Title: Slower sales at debt-laden French retailer Casino sink shares\n",
      "Date Posted: 2023-05-04 07:34AM\n",
      "\n",
      "Title: Datadog stock advances after earnings beat\n",
      "Date Posted: 2023-05-04 07:34AM\n",
      "\n",
      "Title: Papa John’s tops profit expectations, but revenue and same-store sales fall short\n",
      "Date Posted: 2023-05-04 07:31AM\n",
      "\n",
      "Title: Russian rouble soars to one-month high as oil prices halt slide\n",
      "Date Posted: 2023-05-04 07:23AM\n",
      "\n",
      "Title: Regeneron's Eylea drug misses sales estimates as competition heats up\n",
      "Date Posted: 2023-05-04 07:19AM\n",
      "\n",
      "Title: Shopify to cut 20% of its workforce, beats quarterly revenue estimates\n",
      "Date Posted: 2023-05-04 07:12AM\n",
      "\n",
      "Title: Toronto-Dominion Bank, First Horizon Terminate Merger Agreement\n",
      "Date Posted: 2023-05-04 07:08AM\n",
      "\n",
      "Title: IMF to Disburse $300 Million to Kenya After Review Completed\n",
      "Date Posted: 2023-05-04 07:07AM\n",
      "\n",
      "Title: China Asks SOEs to Enhance Security Checks When Picking Auditors\n",
      "Date Posted: 2023-05-04 07:03AM\n",
      "\n",
      "Title: Here’s when history says the post-Fed rally should start — and the two unlikely sectors to benefit\n",
      "Date Posted: 2023-05-04 07:02AM\n",
      "\n",
      "Title: Apollo Agrees to Buy Parts Maker Arconic for About $3 Billion\n",
      "Date Posted: 2023-05-04 07:00AM\n",
      "\n",
      "Title: PacWest, Western Alliance hit as US banking concerns widen\n",
      "Date Posted: 2023-05-04 06:57AM\n",
      "\n",
      "Title: Canadian lender TD calls off $13.4 bln deal to buy First Horizon Bank\n",
      "Date Posted: 2023-05-04 06:53AM\n",
      "\n",
      "Title: Moderna beats COVID vaccine sales expectations as deferred revenue rolls in\n",
      "Date Posted: 2023-05-04 06:42AM\n",
      "\n",
      "Title: Futures waver as PacWest slide offsets Fed pause optimism\n",
      "Date Posted: 2023-05-04 06:31AM\n",
      "\n",
      "Title: BlackRock, LGIM Pick Europe Credit Over US as Bank Woes Deepen\n",
      "Date Posted: 2023-05-04 06:27AM\n",
      "\n",
      "Title: Oil Prices Under Pressure on Economic Fears, Gusher of Russian Supply\n",
      "Date Posted: 2023-05-04 06:24AM\n",
      "\n",
      "Title: Spring homebuyers to continue facing inventory woes\n",
      "Date Posted: 2023-05-04 06:11AM\n",
      "\n",
      "Title: Adani Flagship Profit Jumps 138% as It Moves Past Hindenburg Hit\n",
      "Date Posted: 2023-05-04 06:07AM\n",
      "\n",
      "Title: AMERICAS Hike and hold, bank angst and Apple\n",
      "Date Posted: 2023-05-04 06:05AM\n",
      "\n",
      "Title: Shell Reports $9.6 Billion Profit, Despite Falling Oil Prices\n",
      "Date Posted: 2023-05-04 06:04AM\n",
      "\n",
      "Title: Africa’s Biggest Fund Manager Boosts Gold Fields Stake to 15%\n",
      "Date Posted: 2023-05-04 06:03AM\n",
      "\n",
      "Title: British Gas to stop using contractors to force-fit prepayment meters\n",
      "Date Posted: 2023-05-04 06:01AM\n",
      "\n",
      "Title: US bank seeks buyer as confidence crisis spreads\n",
      "Date Posted: 2023-05-04 05:46AM\n",
      "\n",
      "Title: Swiss Hit With 120 Lawsuits Over Credit Suisse AT1 Bond Wipeout\n",
      "Date Posted: 2023-05-04 05:40AM\n",
      "\n",
      "Title: PacWest tumbles on weighing options, other U.S. regional bank stocks fall\n",
      "Date Posted: 2023-05-04 05:33AM\n",
      "\n",
      "Title: Pick n Pay Plunges as It Girds for $55 Million Extra Power Cost\n",
      "Date Posted: 2023-05-04 05:30AM\n",
      "\n",
      "Title: Warren Buffett Has Been Betting Big on Oil. It's Time to Find Out Why.\n",
      "Date Posted: 2023-05-04 05:30AM\n",
      "\n",
      "Title: Corporate Profit Margins Are Finally Stabilizing\n",
      "Date Posted: 2023-05-04 05:30AM\n",
      "\n",
      "Title: UK Watchdog Aims to Improve Whistleblower Procedures After Backlash\n",
      "Date Posted: 2023-05-04 05:23AM\n",
      "\n",
      "Title: PacWest Stock Crumbles Amid Investor Talks\n",
      "Date Posted: 2023-05-04 05:07AM\n",
      "\n",
      "Title: The U.K. Economy Needs a Pick-Me-Up. Is the Coronation Enough?\n",
      "Date Posted: 2023-05-04 05:00AM\n",
      "\n",
      "Title: Why China’s Censors Are Deleting Videos About Poverty\n",
      "Date Posted: 2023-05-04 05:00AM\n",
      "\n",
      "Title: Even as China Reopens, Security Visits Spook Foreign Businesses\n",
      "Date Posted: 2023-05-04 05:00AM\n",
      "\n",
      "Title: White House Unveils Initiatives to Reduce Risks of AI\n",
      "Date Posted: 2023-05-04 05:00AM\n",
      "\n",
      "Title: Dollar under pressure after Fed, eyes on ECB\n",
      "Date Posted: 2023-05-04 04:57AM\n",
      "\n",
      "Title: Most Gulf bourses in red after Fed rate hike\n",
      "Date Posted: 2023-05-04 04:57AM\n",
      "\n",
      "Title: AIB upgrades guidance after 70% jump in first quarter income\n",
      "Date Posted: 2023-05-04 04:57AM\n",
      "\n",
      "Title: Hong Kong’s Retail Sales Jump in March as Rebound Strengthens\n",
      "Date Posted: 2023-05-04 04:55AM\n",
      "\n",
      "Title: UK's Trainline rises after upbeat FY revenue forecast on travel recovery\n",
      "Date Posted: 2023-05-04 04:46AM\n",
      "\n",
      "Title: UK Mortgage Lending Stalls for First Time Since Pandemic in 2021\n",
      "Date Posted: 2023-05-04 04:41AM\n",
      "\n",
      "Title: London Stock Exchange CEO Says Execs Should Be Paid More to Boost UK\n",
      "Date Posted: 2023-05-04 04:39AM\n",
      "\n",
      "Title: Book profits in Indian equities as U.S. recession imminent - BofA Securities\n",
      "Date Posted: 2023-05-04 04:37AM\n",
      "\n",
      "Title: Novo Nordisk cuts some US supply of obesity drug Wegovy to cope with demand\n",
      "Date Posted: 2023-05-04 04:37AM\n",
      "\n",
      "Title: White House Rejects Kremlin Statement US \"Undoubtedly\" Behind Drone Attack On Kremlin\n",
      "Date Posted: 2023-05-04 10:15AM\n",
      "\n",
      "Title: A \"Pause\" That Does Not Refresh\n",
      "Date Posted: 2023-05-04 09:53AM\n",
      "\n",
      "Title: Which Jobs Will Be Most Impacted By ChatGPT?\n",
      "Date Posted: 2023-05-04 09:35AM\n",
      "\n",
      "Title: Initial Jobless Claims Jump Near 18 Month High\n",
      "Date Posted: 2023-05-04 09:19AM\n",
      "\n",
      "Title: Brace For Rate Impact As Fed Drops Duration Shield\n",
      "Date Posted: 2023-05-04 09:15AM\n",
      "\n",
      "Title: /Panic with Friends - Ben Hunt of Epsilon Theory on Rational Optimism and Countering a Coordinated Attack On The Narrative of the United States\n",
      "Date Posted: 2023-05-04 09:00AM\n",
      "\n",
      "Title: Russia Says US Behind Overnight Drone Attack On Oil Refinery\n",
      "Date Posted: 2023-05-04 08:55AM\n",
      "\n",
      "Title: Market Ignores Fed Chair Powell's Comments, Prices in More Interest Rate Cuts\n",
      "Date Posted: 2023-05-04 08:52AM\n",
      "\n",
      "Title: Trade Deficit decreased to $64.2 Billion in March\n",
      "Date Posted: 2023-05-04 08:49AM\n",
      "\n",
      "Title: Weekly Initial Unemployment Claims increase to 242,000\n",
      "Date Posted: 2023-05-04 08:33AM\n",
      "\n",
      "Title: What If The Fed Has Lost Control?\n",
      "Date Posted: 2023-05-04 08:30AM\n",
      "\n",
      "Title: ECB Hikes Rates By 25bps (As Expected), Warns \"Inflation Continues To Be Too High For Too Long\"\n",
      "Date Posted: 2023-05-04 08:24AM\n",
      "\n",
      "Title: Futures Slide As Fed Pauses Rate Hikes, Regional Banks Resume Plunge\n",
      "Date Posted: 2023-05-04 08:03AM\n",
      "\n",
      "Title: Cloudflare: Bull Case Busted?\n",
      "Date Posted: 2023-05-04 07:52AM\n",
      "\n",
      "Title: Three Things Traders Are Watching From The ECB Today\n",
      "Date Posted: 2023-05-04 07:50AM\n",
      "\n",
      "Title: GMF And EEMA: Risk And Opportunity In Emerging Asian Markets\n",
      "Date Posted: 2023-05-04 06:35AM\n",
      "\n",
      "Title: Southwestern Energy: Undervalued Natural Gas Company\n",
      "Date Posted: 2023-05-04 06:30AM\n",
      "\n",
      "Title: The Absolute Return Partners May 2023 Letter\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Thursday: Unemployment Claims, Trade Balance\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Losses with distribution as resistance holds for the S&P and Nasdaq\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Embark Technology: Does This Tech Stub Cigar Butt Have One Last Puff?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: The Fed’s Final Rate Hike?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Heavy Truck Sales Up Sharply Year-over-year in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: CVS Health: Explaining The Guidance Cut And How To Evaluate It After Q1 Earnings Beat\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Fed Says Banking System is Sound and Resilient, Hikes Interest Rate a Quarter Point\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: FOMC Statement: Raise Rates 25 bp; Pause in June Likely\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: An 86% Chance of Fed Rate Hike Today and a 12% Chance of a Cut in June\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Wednesday links: calling while you can\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: A Record Low 13 Percent of Eighth Grade Students Are Proficient in History\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Black Knight Mortgage Monitor: Home Prices Increased in March; Prices Up 1.0% YoY\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: HVS: Q1 2023 Homeownership and Vacancy Rates; Rental Vacancy Rates Increased Sharply\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ISM® Services Index Increases to 51.9% in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Personal finance links: the need to impress\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: PacWest Bancorp: The Forest And The Trees\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Ford Soundly Beats Earnings Estimates But Shares Decline Anyway, Why?\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: ADP: Private Employment Increased 296,000 in April\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Frienemies ...The Twitter API Wars\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: MBA: Mortgage Applications Decreased in Weekly Survey\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: AGNC: Mortgage Supply/Demand Shifts Will Support The 15% Dividend Yield, Buy\n",
      "Date Posted: May-03\n",
      "\n",
      "Title: Leads And Lags: Timing A Recession\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Another Zombie Bites the Dust\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Job Openings Dive But Quits Tell a Better Story of the Weakening Job Market\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Tuesday links: avoiding burnout\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Research links: effective ETF strategies\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Ferrari Could Be Racing Towards An Earnings Beat\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Technology Comes For Everyone and Every Thing\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: How to Trigger a Bank Crash\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: There's a 94 Percent Chance of a Rate Hike on May 3, Then What?\n",
      "Date Posted: May-02\n",
      "\n",
      "Title: Narrow action for markets does everthing but breakout\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Rickards: Fed’s Looking in Wrong Direction\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Fed Admits a Mistake in Collapse of SVB, Seeks More Power Anyway\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Monday links: a tortured existence\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Manufacturing ISM Contracts Six Straight  Month, New Orders Down Eight Months\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: An Invite You Cannot Refuse, JPMorgan Takes Over First Republic Bank, Big Get Bigger\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Adviser links: starting small\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: Momentum Monday - Is Owning Microsoft, Apple, Nvidia Diversification and The Bull Market In France\n",
      "Date Posted: May-01\n",
      "\n",
      "Title: The Art of Asking the Right Questions\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Nasdaq and S&P launch another attack at resistance as Russell 2000 struggles.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Sunday links: hours wasted\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Happy Birthday Max Lindzon (24) and Sunday Reads And Listens ...The State of US Venture Capital in 2023.\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: Top clicks this week on Abnormal Returns\n",
      "Date Posted: Apr-30\n",
      "\n",
      "Title: We Have Met the Enemy\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: Saturday links: prioritizing fun\n",
      "Date Posted: Apr-29\n",
      "\n",
      "Title: “Something Clearly Went Wrong”\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Living In The Future Via Tel Aviv\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: Friday links: de-risked projects\n",
      "Date Posted: Apr-28\n",
      "\n",
      "Title: “Your Backhanded Support of Tucker Carlson Is Despicable”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: “You’ll Be Poor and Like It, Beggar!”\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Panic with Friends - Oana Manolache, Founder and CEO of Sequel.io, on Empowering Brands with Unique Live Experiences that Connect Customers\n",
      "Date Posted: Apr-27\n",
      "\n",
      "Title: Why We Stand With Tucker Carlson\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: \"Death Cross\" in Russell 2000 as sellers strike markets\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: Good Morning From Tel Aviv...\n",
      "Date Posted: Apr-26\n",
      "\n",
      "Title: “Kill the Whales!”\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: Goodbye South of France...Can't Wait To Come Back\n",
      "Date Posted: Apr-25\n",
      "\n",
      "Title: For today, read yesterday - no change in state of play.\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Momentum Monday - The Degenerate Economy Is Gathering Steam\n",
      "Date Posted: Apr-24\n",
      "\n",
      "Title: Neutral finish to week; indices ready to rally.\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Three Best Practices for Making Lasting Life Changes\n",
      "Date Posted: Apr-23\n",
      "\n",
      "Title: Minor losses keep things close to resistance\n",
      "Date Posted: Apr-20\n",
      "\n",
      "Title: Bearish candlesticks on tags of indices resistance\n",
      "Date Posted: Apr-18\n",
      "\n",
      "Title: A tale of two cities; Nasdaq leads, but Russell 2000 in trouble.\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: How to Assess the Personality of the Stock Market\n",
      "Date Posted: Apr-16\n",
      "\n",
      "Title: What Makes for Success: Five Perspectives From Trading Psychology\n",
      "Date Posted: Apr-09\n",
      "\n",
      "Title: Nasdaq primed for breakout\n",
      "Date Posted: Apr-05\n",
      "\n",
      "Title: Breadth Thrusts in the Stock Market: What Comes Next?\n",
      "Date Posted: Apr-02\n",
      "\n",
      "Title: Understanding Market Themes From Sector Breadth\n",
      "Date Posted: Mar-26\n",
      "\n",
      "Title: Making Passion Your Purpose\n",
      "Date Posted: Mar-19\n",
      "\n",
      "Title: Broad Stock Market Selloff:  What Comes Next?\n",
      "Date Posted: Mar-11\n",
      "\n",
      "Title: The Most Important Factor in Successful Relationships\n",
      "Date Posted: Mar-05\n",
      "\n",
      "Title: New Issue Now Available: What Hedge Funds Bought/Sold in Q1 Volatility\n",
      "Date Posted: May-21\n",
      "\n",
      "The data has been saved to 'news_data_v1.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "url = 'https://finviz.com/news.ashx'  # Replace this with the actual URL of the website\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "    # Create and open the CSV file for writing\n",
    "    with open('news_data_v1.csv', mode='w', newline='', encoding='utf-8-sig') as csv_file:\n",
    "        fieldnames = ['Title', 'Date Posted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the CSV header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Iterate over the news items and write each row to the CSV file\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            # Check if the date_posted is in the time format (e.g., 09:18AM)\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                # If it's a time format, concatenate today's date with the given time\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            print(f\"Title: {title}\\nDate Posted: {date_posted}\\n\")\n",
    "            writer.writerow({'Title': title, 'Date Posted': date_posted})\n",
    "\n",
    "    print(\"The data has been saved to 'news_data_v1.csv'\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575c6de",
   "metadata": {},
   "source": [
    "Lowyat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f99b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Rumours & Leaks\n",
      "Title: Samsung Galaxy S23 FE Main Camera May Receive A Long Awaited Upgrade\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Rumours & Leaks\n",
      "Title: Gigabyte EEC Filing Lists NVIDIA GeForce RTX 4060 Ti, AMD Radeon RX 7600\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Earbuds\n",
      "Title: OnePlus Nord Buds 2R Spotted With SIRIM Certification; Local Launch Likely\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Random As It Gets\n",
      "Title: The MouthPad Is A Wild Input Device That You Control With Your Tongue\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Automotive\n",
      "Title: JPJ Officially Starts Offering 10-Year Driving Licence Renewals\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: Another Motorola Razr 40 Ultra Leak Reveals Its Specs\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: Leak Suggests Samsung Galaxy Z Fold5 To Feature Mostly Unchanged Design\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: iQOO Neo 8 Pro To Reportedly Come With 120W Charging\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: Leakster Shows Off Samsung Galaxy Z Flip5 Unofficial Renders\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Rumours & Leaks\n",
      "Title: Alleged Pricing For ASUS ROG Ally Leaks; Top-Tier Model Retails For US$700\n",
      "Date: April 28, 2023\n",
      "\n",
      "Category: Software\n",
      "Title: Microsoft Says Windows 10 22H2 Is The Final Version For The OS\n",
      "Date: April 28, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: More iPhone 15 Pro CAD Renders Show Volume Buttons With Action Button\n",
      "Date: April 27, 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL you want to scrape\n",
    "url = \"https://www.lowyat.net/news/\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all elements with the class \"jeg_postblock_content\"\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"jeg_postblock_content\")\n",
    "\n",
    "    # Extract and print the content of each element\n",
    "    for block in post_blocks:\n",
    "        category = block.find_previous(\"div\", class_=\"jeg_post_category\")\n",
    "        title = block.find(\"h3\", class_=\"jeg_post_title\")\n",
    "        date = block.find(\"div\", class_=\"jeg_meta_date\")\n",
    "\n",
    "        if category and title and date:\n",
    "            print(\"Category:\", category.get_text().strip())\n",
    "            print(\"Title:\", title.find(\"a\").get_text().strip())\n",
    "            print(\"Date:\", date.get_text().strip())\n",
    "            print()\n",
    "else:\n",
    "    print(f\"Failed to retrieve content. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f03cb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully.\n",
      "Page 2 scraped successfully.\n",
      "Category: Rumours & Leaks\n",
      "Title: Samsung Galaxy S23 FE Main Camera May Receive A Long Awaited Upgrade\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Rumours & Leaks\n",
      "Title: Gigabyte EEC Filing Lists NVIDIA GeForce RTX 4060 Ti, AMD Radeon RX 7600\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Earbuds\n",
      "Title: OnePlus Nord Buds 2R Spotted With SIRIM Certification; Local Launch Likely\n",
      "Date: May 5, 2023\n",
      "\n",
      "Category: Random As It Gets\n",
      "Title: The MouthPad Is A Wild Input Device That You Control With Your Tongue\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Automotive\n",
      "Title: JPJ Officially Starts Offering 10-Year Driving Licence Renewals\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: Another Motorola Razr 40 Ultra Leak Reveals Its Specs\n",
      "Date: May 3, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: Leak Suggests Samsung Galaxy Z Fold5 To Feature Mostly Unchanged Design\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: iQOO Neo 8 Pro To Reportedly Come With 120W Charging\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: Leakster Shows Off Samsung Galaxy Z Flip5 Unofficial Renders\n",
      "Date: May 2, 2023\n",
      "\n",
      "Category: Rumours & Leaks\n",
      "Title: Alleged Pricing For ASUS ROG Ally Leaks; Top-Tier Model Retails For US$700\n",
      "Date: April 28, 2023\n",
      "\n",
      "Category: Software\n",
      "Title: Microsoft Says Windows 10 22H2 Is The Final Version For The OS\n",
      "Date: April 28, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: More iPhone 15 Pro CAD Renders Show Volume Buttons With Action Button\n",
      "Date: April 27, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: POCO F5 Series Leaks In Its Entirety; Pro To Get Smaller Battery Than Redmi K60\n",
      "Date: April 27, 2023\n",
      "\n",
      "Category: Software\n",
      "Title: Microsoft Announces Rollout For Phone Link For iOS On Windows 11\n",
      "Date: April 27, 2023\n",
      "\n",
      "Category: Random\n",
      "Title: NetEase Slaps Blizzard With US$44 Million Lawsuit\n",
      "Date: April 26, 2023\n",
      "\n",
      "Category: Software\n",
      "Title: This Little-Known Microsoft Edge Feature Sends Sites You Visit To Bing\n",
      "Date: April 26, 2023\n",
      "\n",
      "Category: Drone\n",
      "Title: DJI Mavic 3 Pro Officially Launches With RM9799 Starting Price\n",
      "Date: April 25, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: iOS Sideloading May Be Limited To Only The EU\n",
      "Date: April 25, 2023\n",
      "\n",
      "Category: Hardware\n",
      "Title: Seagate Fined US$300 Million For Shipping Millions Of Drives To Huawei\n",
      "Date: April 25, 2023\n",
      "\n",
      "Category: Mobile\n",
      "Title: Clip Featuring Alleged Google Pixel Fold Appears Online\n",
      "Date: April 24, 2023\n",
      "\n",
      "Category: Software\n",
      "Title: Windows 11 Microsoft Defender Update May Be Breaking PC Games’ Anti-Cheat\n",
      "Date: April 20, 2023\n",
      "\n",
      "Category: AI & Robotics\n",
      "Title: Adobe Firefly For Video Adds Generative AI To Video Editing\n",
      "Date: April 18, 2023\n",
      "\n",
      "Category: News\n",
      "Title: PM Anwar Announces Extra Public Holiday, Free Tolls, And Discount On Summons For Raya\n",
      "Date: April 18, 2023\n",
      "\n",
      "Category: Mobile Phones\n",
      "Title: Here’s The Official First Look At The Xiaomi 13 Ultra\n",
      "Date: April 17, 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_data(soup):\n",
    "    data = []\n",
    "    # Find all elements with the class \"jeg_postblock_content\"\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"jeg_postblock_content\")\n",
    "\n",
    "    # Extract the content of each element\n",
    "    for block in post_blocks:\n",
    "        category = block.find_previous(\"div\", class_=\"jeg_post_category\")\n",
    "        title = block.find(\"h3\", class_=\"jeg_post_title\")\n",
    "        date = block.find(\"div\", class_=\"jeg_meta_date\")\n",
    "\n",
    "        if category and title and date:\n",
    "            data.append({\n",
    "                \"Category\": category.get_text().strip(),\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Date\": date.get_text().strip(),\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scrape_pages(base_url, num_pages):\n",
    "    all_data = []\n",
    "    \n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Define the base URL you want to scrape\n",
    "base_url = \"https://www.lowyat.net/news\"\n",
    "num_pages = 2  # Specify the number of pages you want to scrape\n",
    "\n",
    "# Scrape data from the specified number of pages\n",
    "all_data = scrape_pages(base_url, num_pages)\n",
    "\n",
    "# Print the extracted data\n",
    "for item in all_data:\n",
    "    print(\"Category:\", item[\"Category\"])\n",
    "    print(\"Title:\", item[\"Title\"])\n",
    "    print(\"Date:\", item[\"Date\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f64f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully.\n",
      "Page 2 scraped successfully.\n",
      "Page 3 scraped successfully.\n",
      "Page 4 scraped successfully.\n",
      "Page 5 scraped successfully.\n",
      "Data exported to lowyat_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def extract_data(soup):\n",
    "    data = []\n",
    "    # Find all elements with the class \"jeg_postblock_content\"\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"jeg_postblock_content\")\n",
    "\n",
    "    # Extract the content of each element\n",
    "    for block in post_blocks:\n",
    "        category = block.find_previous(\"div\", class_=\"jeg_post_category\")\n",
    "        title = block.find(\"h3\", class_=\"jeg_post_title\")\n",
    "        date = block.find(\"div\", class_=\"jeg_meta_date\")\n",
    "\n",
    "        if category and title and date:\n",
    "            data.append({\n",
    "                \"Category\": category.get_text().strip(),\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Date\": date.get_text().strip(),\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scrape_pages(base_url, num_pages, delay=2):\n",
    "    all_data = []\n",
    "    \n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "        if page_num < num_pages:\n",
    "            time.sleep(delay)  # Add a delay between requests\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def export_to_csv(data, file_name):\n",
    "    with open(file_name, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"Category\", \"Title\", \"Date\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Define the base URL you want to scrape\n",
    "base_url = \"https://www.lowyat.net/news\"\n",
    "num_pages = 5  # Specify the number of pages you want to scrape\n",
    "delay = 5  # Specify the delay between requests in seconds\n",
    "csv_file = \"lowyat_articles.csv\"  # Specify the output CSV file name\n",
    "\n",
    "# Scrape data from the specified number of pages\n",
    "all_data = scrape_pages(base_url, num_pages, delay)\n",
    "\n",
    "# Export the extracted data to a CSV file\n",
    "export_to_csv(all_data, csv_file)\n",
    "\n",
    "print(f\"Data exported to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7eb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowyat: Page 1 scraped successfully.\n",
      "Lowyat: Page 2 scraped successfully.\n",
      "Finviz scraped successfully.\n",
      "TechCrunch scraped successfully.\n",
      "Data exported to combined_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def extract_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"jeg_postblock_content\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        category = block.find_previous(\"div\", class_=\"jeg_post_category\")\n",
    "        title = block.find(\"h3\", class_=\"jeg_post_title\")\n",
    "        date = block.find(\"div\", class_=\"jeg_meta_date\")\n",
    "\n",
    "        if category and title and date:\n",
    "            data.append({\n",
    "                \"Source\": \"Lowyat\",\n",
    "                \"Category\": category.get_text().strip(),\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Date\": date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = extract_techcrunch_data(soup)\n",
    "\n",
    "        print(\"TechCrunch scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"TechCrunch: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_lowyat(base_url, num_pages, delay=2, headers=None):\n",
    "    all_data = []\n",
    "\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Lowyat: Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Lowyat: Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "        if page_num < num_pages:\n",
    "            time.sleep(delay)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def scrape_finviz(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            data.append({\n",
    "                \"Source\": \"Finviz\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title,\n",
    "                \"Date\": date_posted,\n",
    "            })\n",
    "\n",
    "        print(\"Finviz scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Finviz: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def export_to_csv(data, file_name):\n",
    "    with open(file_name, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "        fieldnames = [\"Source\", \"Category\", \"Title\", \"Content\", \"Date\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "base_url = \"https://www.lowyat.net/news\"\n",
    "num_pages = 2\n",
    "delay = 5\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "lowyat_data = scrape_lowyat(base_url, num_pages, delay, headers)\n",
    "\n",
    "finviz_url = \"https://finviz.com/news.ashx\"\n",
    "finviz_headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "finviz_data = scrape_finviz(finviz_url, finviz_headers)\n",
    "\n",
    "# Specify the URL of the TechCrunch website\n",
    "techcrunch_url = \"https://techcrunch.com/\"\n",
    "\n",
    "# Headers for the requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Scrape data from TechCrunch\n",
    "techcrunch_data = scrape_techcrunch(techcrunch_url, headers)\n",
    "\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = lowyat_data + finviz_data + techcrunch_data\n",
    "\n",
    "# Export the combined data to a CSV file\n",
    "csv_file = \"combined_articles.csv\"  # Specify the output CSV file name\n",
    "export_to_csv(all_data, csv_file)\n",
    "\n",
    "print(f\"Data exported to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49dc22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TechCrunch scraped successfully.\n",
      "Title: Google and OpenAI are Walmarts besieged by fruit stands\n",
      "Content: OpenAI may be synonymous with machine learning now and Google is doing its best to pick itself up off the floor, but both may soon face a new threat: rapidly multiplying open source projects that push\n",
      "Date: 2023-05-05T16:21:27-07:00\n",
      "\n",
      "Title: Hacked verified Facebook pages impersonating Meta are buying ads from Meta\n",
      "Content: Sketchy Facebook pages impersonating businesses are nothing new, but a flurry of recent scams is particularly brazen. A handful of verified Facebook pages were hacked recently and spotted slinging lik\n",
      "Date: 2023-05-05T16:00:57-07:00\n",
      "\n",
      "Title: Twitter confirms Circle tweets temporarily were not private\n",
      "Content: Twitter confirmed that a security error that made Circle tweets — posts that only go out to a small subset of trusted friends — surface publicly. TechCrunch reported the glitch in early Ap\n",
      "Date: 2023-05-05T15:31:13-07:00\n",
      "\n",
      "Title: Daily Crunch: New AI model DeepFloyd IF offers ‘advanced text-to-image generation techniques’\n",
      "Content: Hello, friends, and welcome to Daily Crunch, bringing you the most important startup, tech and venture capital news in a single package.\n",
      "Date: 2023-05-05T15:05:36-07:00\n",
      "\n",
      "Title: Confusion sets in as Meta content moderators go without pay\n",
      "Content: Content moderators under Sama, Meta’s content review sub-contractor in Africa, earlier today picketed at the company’s headquarters in Kenya demanding April salary, while urging it to obse\n",
      "Date: 2023-05-05T13:52:08-07:00\n",
      "\n",
      "Title: Amazon quietly acquired audio content discovery engine Snackable AI to boost its podcast projects\n",
      "Content: Amazon quietly acquired New York–based audio content discovery engine Snackable AI last December to boost its podcast features, as first reported by New York Post. The tech giant told TechCrunch in\n",
      "Date: 2023-05-05T12:47:41-07:00\n",
      "\n",
      "Title: Why Halo is betting on a remote-operated car-sharing service\n",
      "Content: Driverless cars are often marketed as a safe and convenient means of travel that allows customers to watch movies, scroll through TikTok or nap — all without worrying about taking over control. Whet\n",
      "Date: 2023-05-05T12:06:40-07:00\n",
      "\n",
      "Title: Think of the monetized children and other TC news\n",
      "Content: Meta is monetizing kids as much as they are the rest of us. But this week the US Federal Trade Commission (FTC) has alleged that Meta violated a 2020 order to protect kids on the site as well as, runn\n",
      "Date: 2023-05-05T12:00:26-07:00\n",
      "\n",
      "Title: Amazon’s TikTok-like Inspire shopping feed is now available to all customers in the US\n",
      "Content: Amazon’s in-app TikTok-like shopping feed is now available to all customers in the United States, according to the company’s website. The feature rolled out to select U.S. customers in Dec\n",
      "Date: 2023-05-05T10:28:52-07:00\n",
      "\n",
      "Title: Vint Cerf on the ‘exhilarating mix’ of thrill and hazard at the frontiers of tech\n",
      "Content: Vint Cerf has been a near-constant influence on the internet since the days when he was helping create it in the first place. Today he wears many hats, among them VP and chief internet evangelist at G\n",
      "Date: 2023-05-05T10:16:02-07:00\n",
      "\n",
      "Title: TechCrunch+ roundup: AI ethics investor survey, B2B SaaS KPIs, don’t frown on down rounds\n",
      "Content: Because AI requires human input, it is inherently susceptible to bias. What are investors doing to hold founders accountable?\n",
      "Date: 2023-05-05T10:14:55-07:00\n",
      "\n",
      "Title: Google I/O 2023 is next week; here’s what we’re expecting\n",
      "Content: Google’s annual developer conference, Google I/O, returns to Mountain View’s Shoreline Amphitheater next week, and for the first time in four years, we’ll be returning along with it. The kickoff\n",
      "Date: 2023-05-05T09:52:46-07:00\n",
      "\n",
      "Title: Paytm tops $977 million revenue in a year, narrows loss\n",
      "Content: Paytm, India’s leading mobile payments firm, reported a 13.2% surge in revenue to $285.7 million in the quarter ending March and pared its loss by 57% to $20.5 million in a sharp turnaround for\n",
      "Date: 2023-05-05T09:29:31-07:00\n",
      "\n",
      "Title: RapidAPI headcount down 82% from fresh layoffs less than two weeks after cutting 50% of staff\n",
      "Content: Rapid (previously known as RapidAPI), a startup that built out an API marketplace valued at $1 billion last year, has laid off another 70 employees less than two weeks after letting go of 50% of its s\n",
      "Date: 2023-05-05T09:26:01-07:00\n",
      "\n",
      "Title: Hear how MinIO built a unicorn in object storage on top of Kubernetes and open source\n",
      "Content: Everything needs a home, and Garima Kapoor co-founded MinIO to build an enterprise-grade, open source object storage solution. The pitch sounds amazing: simple, high performance, and a native Kubernet\n",
      "Date: 2023-05-05T09:22:42-07:00\n",
      "\n",
      "Title: Tepid investor reaction clouds Lyft’s new strategy\n",
      "Content: This Friday morning we’re parsing Lyft’s Q1 results and Q2 guidance, the latter of which we’ll place in context of its strategic choices moving forward.\n",
      "Date: 2023-05-05T09:00:34-07:00\n",
      "\n",
      "Title: Down rounds are a ‘ticket to try again,’ says founder who raised 3 in a row\n",
      "Content: Russ Wilcox, founder of E Ink, recently joined TechCrunch's Found podcast to talk about how he raised multiple down rounds before a successful exit.\n",
      "Date: 2023-05-05T08:00:37-07:00\n",
      "\n",
      "Title: Ex-Fin Capital general partner, who led its investment in Pipe, starts new venture firm\n",
      "Content: Peter Ackerson has departed from his role as general partner at fintech-focused venture firm Fin Capital and started a new firm, Audere Capital. According to his LinkedIn profile, Ackerson — who\n",
      "Date: 2023-05-05T07:43:05-07:00\n",
      "\n",
      "Title: TechCrunch Disrupt early-bird savings end in 7 days\n",
      "Content: Most early-stage startup founders, investors, technologists and all-around aficionados recognize and appreciate a great deal. We’re flagging this one, folks, because you have just one week left to t\n",
      "Date: 2023-05-05T07:30:59-07:00\n",
      "\n",
      "Title: What is Bluesky? Everything to know about the app trying to replace Twitter\n",
      "Content: Is the grass greener on the other side? We’re not sure, but the sky is most certainly bluer. It’s been over a year since Elon Musk announced his bid to buy Twitter, and those who opposed the sale\n",
      "Date: 2023-05-05T07:05:31-07:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = extract_techcrunch_data(soup)\n",
    "\n",
    "        print(\"TechCrunch scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"TechCrunch: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Specify the URL of the TechCrunch website\n",
    "techcrunch_url = \"https://techcrunch.com/\"\n",
    "\n",
    "# Headers for the requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Scrape data from TechCrunch\n",
    "techcrunch_data = scrape_techcrunch(techcrunch_url, headers)\n",
    "\n",
    "# Print the data\n",
    "for article in techcrunch_data:\n",
    "    print(f\"Title: {article['Title']}\\nContent: {article['Content']}\\nDate: {article['Date']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508cd13c",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/webscraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:72\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_line_args())\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWindows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/webscraper/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/webscraper/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ongaunter/Desktop/chromedriver.exe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m }\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Scrape data from TechCrunch\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m techcrunch_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_techcrunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtechcrunch_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Print the data\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m techcrunch_data:\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mscrape_techcrunch\u001b[0;34m(url, headers, load_more_clicks, delay)\u001b[0m\n\u001b[1;32m     34\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--disable-gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/ongaunter/Desktop/chromedriver.exe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(load_more_clicks):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/webscraper/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:73\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     66\u001b[0m         desired_capabilities\u001b[38;5;241m.\u001b[39mupdate(options\u001b[38;5;241m.\u001b[39mto_capabilities())\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m Service(\n\u001b[1;32m     69\u001b[0m     executable_path,\n\u001b[1;32m     70\u001b[0m     port\u001b[38;5;241m=\u001b[39mport,\n\u001b[1;32m     71\u001b[0m     service_args\u001b[38;5;241m=\u001b[39mservice_args,\n\u001b[1;32m     72\u001b[0m     log_path\u001b[38;5;241m=\u001b[39mservice_log_path)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     RemoteWebDriver\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m         command_executor\u001b[38;5;241m=\u001b[39mChromeRemoteConnection(\n\u001b[1;32m     79\u001b[0m             remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     80\u001b[0m             keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive),\n\u001b[1;32m     81\u001b[0m         desired_capabilities\u001b[38;5;241m=\u001b[39mdesired_capabilities)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/webscraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable needs to be in PATH. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     83\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEACCES:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable may have wrong permissions. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     88\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[1;32m     89\u001b[0m         )\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers, load_more_clicks=5, delay=2):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(f\"user-agent={headers['User-Agent']}\")\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=r\"/Users/ongaunter/Desktop/chromedriver.exe\", options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    for i in range(load_more_clicks):\n",
    "        load_more_button = driver.find_element_by_class_name(\"load-more\")\n",
    "\n",
    "        if load_more_button:\n",
    "            load_more_button.click()\n",
    "            time.sleep(delay)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    driver.quit()\n",
    "\n",
    "    data = extract_techcrunch_data(soup)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Specify the URL of the TechCrunch website\n",
    "techcrunch_url = \"https://techcrunch.com/\"\n",
    "\n",
    "# Headers for the requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Scrape data from TechCrunch\n",
    "techcrunch_data = scrape_techcrunch(techcrunch_url, headers)\n",
    "\n",
    "# Print the data\n",
    "for article in techcrunch_data:\n",
    "    print(f\"Title: {article['Title']}\\nContent: {article['Content']}\\nDate: {article['Date']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b593f",
   "metadata": {},
   "source": [
    "# Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7302095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowyat: Page 1 scraped successfully.\n",
      "Lowyat: Page 2 scraped successfully.\n",
      "Finviz scraped successfully.\n",
      "TechCrunch scraped successfully.\n",
      "Data exported to combined_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def extract_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"jeg_postblock_content\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        category = block.find_previous(\"div\", class_=\"jeg_post_category\")\n",
    "        title = block.find(\"h3\", class_=\"jeg_post_title\")\n",
    "        date = block.find(\"div\", class_=\"jeg_meta_date\")\n",
    "\n",
    "        if category and title and date:\n",
    "            data.append({\n",
    "                \"Source\": \"Lowyat\",\n",
    "                \"Category\": category.get_text().strip(),\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Date\": date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = extract_techcrunch_data(soup)\n",
    "\n",
    "        print(\"TechCrunch scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"TechCrunch: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_lowyat(base_url, num_pages, delay=2, headers=None):\n",
    "    all_data = []\n",
    "\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Lowyat: Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Lowyat: Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "        if page_num < num_pages:\n",
    "            time.sleep(delay)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def scrape_finviz(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            data.append({\n",
    "                \"Source\": \"Finviz\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title,\n",
    "                \"Date\": date_posted,\n",
    "            })\n",
    "\n",
    "        print(\"Finviz scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Finviz: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def export_to_csv(data, file_name):\n",
    "    with open(file_name, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "        fieldnames = [\"Source\", \"Category\", \"Title\", \"Content\", \"Date\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "base_url = \"https://www.lowyat.net/news\"\n",
    "num_pages = 2\n",
    "delay = 5\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "lowyat_data = scrape_lowyat(base_url, num_pages, delay, headers)\n",
    "\n",
    "finviz_url = \"https://finviz.com/news.ashx\"\n",
    "finviz_headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "finviz_data = scrape_finviz(finviz_url, finviz_headers)\n",
    "\n",
    "# Specify the URL of the TechCrunch website\n",
    "techcrunch_url = \"https://techcrunch.com/\"\n",
    "\n",
    "# Headers for the requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Scrape data from TechCrunch\n",
    "techcrunch_data = scrape_techcrunch(techcrunch_url, headers)\n",
    "\n",
    "\n",
    "# Combine both datasets\n",
    "all_data = lowyat_data + finviz_data + techcrunch_data\n",
    "\n",
    "# Export the combined data to a CSV file\n",
    "csv_file = \"combined_articles.csv\"  # Specify the output CSV file name\n",
    "export_to_csv(all_data, csv_file)\n",
    "\n",
    "print(f\"Data exported to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76481ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.lowyat.net/news scraped successfully.\n",
      "https://techcrunch.com/ scraped successfully.\n",
      "Finviz scraped successfully.\n",
      "Data exported to combined_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def create_soup(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} while fetching the url {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_data(soup, div_class, title_class, content_class, date_class):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=div_class)\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h3\", class_=title_class) or block.find(\"h2\", class_=title_class)\n",
    "        content = block.find(\"div\", class_=content_class)\n",
    "        date = block.find(\"div\", class_=date_class) or block.find(\"time\", class_=date_class)\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"Source\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip() if date.get(\"datetime\") else date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_website(url, headers, div_class, title_class, content_class, date_class):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_data(soup, div_class, title_class, content_class, date_class)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_finviz(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            data.append({\n",
    "                \"Source\": \"Finviz\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title,\n",
    "                \"Date\": date_posted,\n",
    "            })\n",
    "\n",
    "        print(\"Finviz scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Finviz: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def export_to_csv(data, file_name, title_file):\n",
    "    if os.path.isfile(file_name):\n",
    "        df_old = pd.read_csv(file_name)\n",
    "        df_new = pd.DataFrame(data)\n",
    "        df_combined = pd.concat([df_old, df_new])\n",
    "        df_combined.drop_duplicates(subset=[\"Title\"], inplace=True, keep=\"last\")\n",
    "    else:\n",
    "        df_combined = pd.DataFrame(data)\n",
    "\n",
    "    df_combined.to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "    df_combined.to_csv(title_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Data exported to {file_name}\")\n",
    "\n",
    "# Scrape the websites\n",
    "lowyat_data = scrape_website(\"https://www.lowyat.net/news\", HEADERS, \"jeg_postblock_content\", \"jeg_post_title\", \"\", \"jeg_meta_date\")\n",
    "techcrunch_data = scrape_website(\"https://techcrunch.com/\", HEADERS, \"post-block\", \"post-block__title\", \"post-block__content\", \"river-byline__time\")\n",
    "finviz_data = scrape_finviz(\"https://finviz.com/news.ashx\", HEADERS)\n",
    "\n",
    "# Combine all data\n",
    "all_data = lowyat_data + techcrunch_data + finviz_data\n",
    "\n",
    "# Export to CSV files\n",
    "export_to_csv(all_data, \"combined_articles.csv\", \"article_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def create_soup(url, headers):\n",
    "    time.sleep(random.uniform(1, 3))  # sleep for a random duration between 1 and 3 seconds before making a request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} while fetching the url {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_data(soup, div_class, title_class, content_class, date_class):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=div_class)\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h3\", class_=title_class) or block.find(\"h2\", class_=title_class)\n",
    "        content = block.find(\"div\", class_=content_class)\n",
    "        date = block.find(\"div\", class_=date_class) or block.find(\"time\", class_=date_class)\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"Source\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip() if date.get(\"datetime\") else date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_website(url, headers, div_class, title_class, content_class, date_class):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_data(soup, div_class, title_class, content_class, date_class)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_finviz(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            data.append({\n",
    "                \"Source\": \"Finviz\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title,\n",
    "                \"Date\": date_posted,\n",
    "            })\n",
    "\n",
    "        print(\"Finviz scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Finviz: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def export_to_csv(data, file_name, title_file):\n",
    "    if os.path.isfile(file_name):\n",
    "        df_old = pd.read_csv(file_name)\n",
    "        df_new = pd.DataFrame(data)\n",
    "        df_combined = pd.concat([df_old, df_new])\n",
    "        df_combined.drop_duplicates(subset=[\"Title\"], inplace=True, keep=\"last\")\n",
    "    else:\n",
    "        df_combined = pd.DataFrame(data)\n",
    "\n",
    "    df_combined.to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "    df_combined.to_csv(title_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Data exported to {file_name}\")\n",
    "\n",
    "# Scrape the websites\n",
    "lowyat_data = scrape_website(\"https://www.lowyat.net/news\", HEADERS, \"jeg_postblock_content\", \"jeg_post_title\", \"\", \"jeg_meta_date\")\n",
    "techcrunch_data = scrape_website(\"https://techcrunch.com/\", HEADERS, \"post-block\", \"post-block__title\", \"post-block__content\", \"river-byline__time\")\n",
    "finviz_data = scrape_finviz(\"https://finviz.com/news.ashx\", HEADERS)\n",
    "\n",
    "# Combine all data\n",
    "all_data = lowyat_data + techcrunch_data + finviz_data\n",
    "\n",
    "# Export to CSV files\n",
    "export_to_csv(all_data, \"combined_articles.csv\", \"article_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2052be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3f7974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.lowyat.net/news scraped successfully.\n",
      "https://techcrunch.com/ scraped successfully.\n",
      "https://www.theguardian.com/international scraped successfully.\n",
      "https://www.theguardian.com/world scraped successfully.\n",
      "https://www.bbc.com/news/world scraped successfully.\n",
      "https://www.wsj.com/ scraped successfully.\n",
      "Data exported to combined_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def create_soup(url, headers):\n",
    "#     time.sleep(random.uniform(5, 10))  # sleep for a random duration between 5 and 10 seconds before making a request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} while fetching the url {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_data(soup, div_class, title_class, content_class, date_class, source):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=div_class)\n",
    "\n",
    "    for block in post_blocks:\n",
    "#         time.sleep(random.uniform(5, 10))  # sleep for a random duration between 5 and 10 seconds before processing each block\n",
    "        title = block.find(\"h3\", class_=title_class) or block.find(\"h2\", class_=title_class)\n",
    "        content = block.find(\"div\", class_=content_class)\n",
    "        date = block.find(\"div\", class_=date_class) or block.find(\"time\", class_=date_class)\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": source,\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip() if date.get(\"datetime\") else date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_guardian_data(soup):\n",
    "    data = []\n",
    "    # Find all `ul` tags containing news\n",
    "    news_blocks = soup.find_all(\"ul\")\n",
    "\n",
    "    # Iterate over news_blocks and extract data\n",
    "    for block in news_blocks:\n",
    "        li_tags = block.find_all(\"li\")\n",
    "\n",
    "        for li in li_tags:\n",
    "            a_tag = li.find(\"a\")\n",
    "            h3_tag = li.find(\"h3\")\n",
    "\n",
    "            if a_tag is not None and h3_tag is not None:\n",
    "                link = a_tag['href']\n",
    "                title = h3_tag.text.strip()\n",
    "\n",
    "                # append the data to the list\n",
    "                data.append({\n",
    "                    \"Source\": \"The Guardian\",\n",
    "                    \"Category\": \"\",\n",
    "                    \"Title\": title,\n",
    "                    \"Content\": \"\",\n",
    "                    \"Date\": \"\",  # The date field needs to be fetched separately.\n",
    "                    \"Link\": link,\n",
    "                })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_website(url, headers, div_class, title_class, content_class, date_class, source):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_data(soup, div_class, title_class, content_class, date_class, source)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_guardian(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_guardian_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = extract_techcrunch_data(soup)\n",
    "\n",
    "        print(\"TechCrunch scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"TechCrunch: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_lowyat(base_url, num_pages, delay=2, headers=None):\n",
    "    all_data = []\n",
    "\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Lowyat: Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Lowyat: Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "        if page_num < num_pages:\n",
    "            time.sleep(delay)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_bbc_data(soup):\n",
    "    news_items = []\n",
    "\n",
    "    # Look for divs containing the news items\n",
    "    for news_item in soup.find_all('div', class_='gs-c-promo-body'):\n",
    "        title_element = news_item.find_previous('h3', class_='gs-c-promo-heading__title')\n",
    "        summary_element = news_item.find('p', class_='gs-c-promo-summary')\n",
    "\n",
    "        # Check if it's a valid news item by checking if it contains a title and summary\n",
    "        if title_element and summary_element:\n",
    "            title = title_element.text.strip()\n",
    "            summary = summary_element.text.strip()\n",
    "\n",
    "            news_items.append({'title': title, 'summary': summary})\n",
    "    \n",
    "    return news_items\n",
    "\n",
    "def scrape_bbc(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_bbc_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scrape the websites\n",
    "lowyat_data = scrape_website(\"https://www.lowyat.net/news\", HEADERS, \"jeg_postblock_content\", \"jeg_post_title\", \"\", \"jeg_meta_date\", \"Lowyat\")\n",
    "techcrunch_data = scrape_website(\"https://techcrunch.com/\", HEADERS, \"post-block\", \"post-block__title\", \"post-block__content\", \"river-byline__time\", \"TechCrunch\")\n",
    "guardian_international_data = scrape_guardian(\"https://www.theguardian.com/international\", HEADERS)\n",
    "guardian_world_data = scrape_guardian(\"https://www.theguardian.com/world\", HEADERS)\n",
    "bbc_data = scrape_bbc(\"https://www.bbc.com/news/world\", HEADERS)\n",
    "\n",
    "\n",
    "\n",
    "# Combine all data\n",
    "all_data = lowyat_data + techcrunch_data + guardian_international_data + guardian_world_data + bbc_data + WSJ_data\n",
    "\n",
    "\n",
    "# Export to CSV files\n",
    "def export_to_csv(data, file_name, title_file):\n",
    "    if os.path.isfile(file_name):\n",
    "        df_old = pd.read_csv(file_name)\n",
    "        df_new = pd.DataFrame(data)\n",
    "        df_combined = pd.concat([df_old, df_new])\n",
    "        df_combined.drop_duplicates(subset=[\"Title\"], inplace=True, keep=\"last\")\n",
    "    else:\n",
    "        df_combined = pd.DataFrame(data)\n",
    "\n",
    "    df_combined.to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "    df_combined.to_csv(title_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Data exported to {file_name}\")\n",
    "\n",
    "export_to_csv(all_data, \"combined_articles.csv\", \"article_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bee13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6fce6d",
   "metadata": {},
   "source": [
    "# Working Code V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5868ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.lowyat.net/news scraped successfully.\n",
      "https://techcrunch.com/ scraped successfully.\n",
      "https://www.theguardian.com/international scraped successfully.\n",
      "https://www.theguardian.com/world scraped successfully.\n",
      "https://www.bbc.com/news/world scraped successfully.\n",
      "https://www.wsj.com/ scraped successfully.\n",
      "https://finviz.com/news.ashx scraped successfully.\n",
      "https://www.engadget.com/ scraped successfully.\n",
      "https://www.scmp.com/asia scraped successfully.\n",
      "Data exported to combined_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def create_soup(url, headers):\n",
    "#     time.sleep(random.uniform(5, 10))  # sleep for a random duration between 5 and 10 seconds before making a request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} while fetching the url {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_data(soup, div_class, title_class, content_class, date_class, source):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=div_class)\n",
    "\n",
    "    for block in post_blocks:\n",
    "#         time.sleep(random.uniform(5, 10))  # sleep for a random duration between 5 and 10 seconds before processing each block\n",
    "        title = block.find(\"h3\", class_=title_class) or block.find(\"h2\", class_=title_class)\n",
    "        content = block.find(\"div\", class_=content_class)\n",
    "        date = block.find(\"div\", class_=date_class) or block.find(\"time\", class_=date_class)\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": source,\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip() if date.get(\"datetime\") else date.get_text().strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_guardian_data(soup):\n",
    "    data = []\n",
    "    # Find all `ul` tags containing news\n",
    "    news_blocks = soup.find_all(\"ul\")\n",
    "\n",
    "    # Iterate over news_blocks and extract data\n",
    "    for block in news_blocks:\n",
    "        li_tags = block.find_all(\"li\")\n",
    "\n",
    "        for li in li_tags:\n",
    "            a_tag = li.find(\"a\")\n",
    "            h3_tag = li.find(\"h3\")\n",
    "\n",
    "            if a_tag is not None and h3_tag is not None:\n",
    "                link = a_tag['href']\n",
    "                title = h3_tag.text.strip()\n",
    "\n",
    "                # append the data to the list\n",
    "                data.append({\n",
    "                    \"Source\": \"The Guardian\",\n",
    "                    \"Category\": \"\",\n",
    "                    \"Title\": title,\n",
    "                    \"Content\": \"\",\n",
    "                    \"Date\": \"\",  # The date field needs to be fetched separately.\n",
    "                    \"Link\": link,\n",
    "                })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_website(url, headers, div_class, title_class, content_class, date_class, source):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_data(soup, div_class, title_class, content_class, date_class, source)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_guardian(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_guardian_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "def extract_techcrunch_data(soup):\n",
    "    data = []\n",
    "    post_blocks = soup.find_all(\"div\", class_=\"post-block\")\n",
    "\n",
    "    for block in post_blocks:\n",
    "        title = block.find(\"h2\", class_=\"post-block__title\")\n",
    "        content = block.find(\"div\", class_=\"post-block__content\")\n",
    "        date = block.find(\"time\", class_=\"river-byline__time\")\n",
    "\n",
    "        if title and content and date:\n",
    "            data.append({\n",
    "                \"Source\": \"TechCrunch\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title.find(\"a\").get_text().strip(),\n",
    "                \"Content\": content.get_text().strip(),\n",
    "                \"Date\": date.get(\"datetime\").strip(),\n",
    "            })\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_techcrunch(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = extract_techcrunch_data(soup)\n",
    "\n",
    "        print(\"TechCrunch scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"TechCrunch: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_lowyat(base_url, num_pages, delay=2, headers=None):\n",
    "    all_data = []\n",
    "\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_num}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            data = extract_data(soup)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Lowyat: Page {page_num} scraped successfully.\")\n",
    "        else:\n",
    "            print(f\"Lowyat: Failed to retrieve content from page {page_num}. Status code: {response.status_code}\")\n",
    "\n",
    "        if page_num < num_pages:\n",
    "            time.sleep(delay)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_bbc_data(soup):\n",
    "    news_items = []\n",
    "\n",
    "    # Look for divs containing the news items\n",
    "    for news_item in soup.find_all('div', class_='gs-c-promo-body'):\n",
    "        title_element = news_item.find_previous('h3', class_='gs-c-promo-heading__title')\n",
    "        summary_element = news_item.find('p', class_='gs-c-promo-summary')\n",
    "\n",
    "        # Check if it's a valid news item by checking if it contains a title and summary\n",
    "        if title_element and summary_element:\n",
    "            title = title_element.text.strip()\n",
    "            summary = summary_element.text.strip()\n",
    "\n",
    "            news_items.append({'title': title, 'summary': summary})\n",
    "    \n",
    "    return news_items\n",
    "\n",
    "def scrape_bbc(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_bbc_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    \n",
    "def create_soup_wsj(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.content\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to reach {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_wsj_data(soup):\n",
    "    news_items = []\n",
    "\n",
    "    for news_item in soup.find_all('article', recursive=True):\n",
    "        if news_item.h3 and news_item.h3.a:\n",
    "            title = news_item.h3.a.text.strip()\n",
    "\n",
    "            summary_element = news_item.find('p', {'class': 'WSJTheme--summary--lmOXEsbN'})\n",
    "            summary = summary_element.text.strip() if summary_element else 'No summary available'\n",
    "\n",
    "            news_items.append({\"Source\": \"WSJ\", \"Category\": \"\", \"Title\": title, \"Content\": summary, \"Date\": \"\"})\n",
    "    \n",
    "    return news_items\n",
    "\n",
    "def scrape_wsj(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    if soup:\n",
    "        data = extract_wsj_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def scrape_finviz(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        news_items = soup.select('.table-fixed tr.nn')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            date_posted = news_item.find(class_='nn-date').text.strip()\n",
    "            title = news_item.find('a', class_='nn-tab-link').text.strip()\n",
    "\n",
    "            time_pattern = re.compile(r\"\\d{2}:\\d{2}[AP]M\")\n",
    "            if time_pattern.match(date_posted):\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                date_posted = f\"{today} {date_posted}\"\n",
    "\n",
    "            data.append({\n",
    "                \"Source\": \"Finviz\",\n",
    "                \"Category\": \"\",\n",
    "                \"Title\": title,\n",
    "                \"Date\": date_posted,\n",
    "            })\n",
    "\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Finviz: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def scrape_engadget(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        news_items = soup.find_all('article', recursive=True)\n",
    "\n",
    "        for news_item in news_items:\n",
    "            heading_tag = None\n",
    "\n",
    "            # Find the appropriate heading tag\n",
    "            for i in range(1, 7):\n",
    "                if news_item.find(f'h{i}'):\n",
    "                    heading_tag = news_item.find(f'h{i}')\n",
    "                    break\n",
    "\n",
    "            if heading_tag and heading_tag.a:\n",
    "                title = heading_tag.a.text.strip()\n",
    "\n",
    "                summary_element = news_item.find('p')\n",
    "                summary = summary_element.text.strip() if summary_element else 'No summary available'\n",
    "\n",
    "                date_element = news_item.find('time') or news_item.find('span', {'class': 'date'})  # Replace 'date' with the actual class name\n",
    "                date = date_element.text.strip() if date_element else 'No date available'\n",
    "\n",
    "                data.append({\"Source\": \"Engadget\", \"Title\": title, \"Summary\": summary, \"Date\": date})\n",
    "\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "    else:\n",
    "        print(f\"Engadget: Error: {response.status_code}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_soup_scmp(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return BeautifulSoup(response.text, 'html.parser') if response.status_code == 200 else None\n",
    "\n",
    "def scrape_scmp(url, headers):\n",
    "    soup = create_soup_scmp(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        # Extract titles from 'a' tags\n",
    "        a_news_items = soup.find_all('a')\n",
    "\n",
    "        for news_item in a_news_items:\n",
    "            if 'href' in news_item.attrs and 'scmp.com/news/' in news_item['href']:\n",
    "                title = news_item.text.strip()\n",
    "                article_url = news_item['href']\n",
    "                data.append({\"Source\": \"SCMP\", \"Title\": title, \"Article URL\": article_url})\n",
    "\n",
    "        # Extract titles from 'div' tags\n",
    "        div_news_items = soup.find_all('div', class_='link__headline headline')\n",
    "\n",
    "        for div_news_item in div_news_items:\n",
    "            title = div_news_item.text.strip()\n",
    "            data.append({\"Source\": \"SCMP\", \"Title\": title, \"Article URL\": \"URL not available\"})\n",
    "\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "    else:\n",
    "        print(\"SCMP: Error in request\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Scrape the websites\n",
    "lowyat_data = scrape_website(\"https://www.lowyat.net/news\", HEADERS, \"jeg_postblock_content\", \"jeg_post_title\", \"\", \"jeg_meta_date\", \"Lowyat\")\n",
    "techcrunch_data = scrape_website(\"https://techcrunch.com/\", HEADERS, \"post-block\", \"post-block__title\", \"post-block__content\", \"river-byline__time\", \"TechCrunch\")\n",
    "guardian_international_data = scrape_guardian(\"https://www.theguardian.com/international\", HEADERS)\n",
    "guardian_world_data = scrape_guardian(\"https://www.theguardian.com/world\", HEADERS)\n",
    "bbc_data = scrape_bbc(\"https://www.bbc.com/news/world\", HEADERS)\n",
    "wsj_data = scrape_wsj(\"https://www.wsj.com/\", HEADERS)\n",
    "finviz_data = scrape_finviz(\"https://finviz.com/news.ashx\", HEADERS)\n",
    "engadget_data = scrape_engadget(\"https://www.engadget.com/\", HEADERS)\n",
    "scmp_data = scrape_scmp(\"https://www.scmp.com/asia\", HEADERS)\n",
    "\n",
    "\n",
    "\n",
    "# Combine all data\n",
    "all_data = lowyat_data + finviz_data + techcrunch_data + guardian_international_data + guardian_world_data + bbc_data + wsj_data + engadget_data + scmp_data\n",
    "\n",
    "\n",
    "# Export to CSV files\n",
    "def export_to_csv(data, file_name, title_file):\n",
    "    if os.path.isfile(file_name):\n",
    "        df_old = pd.read_csv(file_name)\n",
    "        df_new = pd.DataFrame(data)\n",
    "        df_combined = pd.concat([df_old, df_new])\n",
    "        df_combined.drop_duplicates(subset=[\"Title\"], inplace=True, keep=\"last\")\n",
    "    else:\n",
    "        df_combined = pd.DataFrame(data)\n",
    "\n",
    "    df_combined.to_csv(file_name, index=False, encoding=\"utf-8-sig\")\n",
    "    df_combined.to_csv(title_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Data exported to {file_name}\")\n",
    "\n",
    "export_to_csv(all_data, \"combined_articles.csv\", \"article_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "393f1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('article_titles.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Define a function to parse the dates from the 'Date' column\n",
    "def parse_date(date_string):\n",
    "    if isinstance(date_string, str):\n",
    "        try:\n",
    "            return datetime.strptime(date_string, '%B %d, %Y').strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'Date' column\n",
    "data['Date'] = data['Date'].apply(parse_date)\n",
    "\n",
    "# Define a function to parse the dates from the URLs in the 'Link' column\n",
    "def extract_date_from_url(url):\n",
    "    if isinstance(url, str):\n",
    "        match = re.search(r\"/(\\d{4})/(\\w+)/(\\d+)\", url)\n",
    "        if match:\n",
    "            # Convert the month name to a number, assuming English month names\n",
    "            month = datetime.strptime(match.group(2), \"%b\").month\n",
    "            # Return the date in 'YYYY-MM-DD' format\n",
    "            return f\"{match.group(1)}-{month:02d}-{match.group(3)}\"\n",
    "    return None\n",
    "\n",
    "# Apply the function to the 'Link' column\n",
    "data['Date_from_Link'] = data['Link'].apply(extract_date_from_url)\n",
    "\n",
    "# Fill missing values in the 'Date' column with the dates extracted from the 'Link' column\n",
    "data['Date'].fillna(data['Date_from_Link'], inplace=True)\n",
    "\n",
    "# Fill remaining missing values in the 'Date' column with today's date\n",
    "data['Date'].fillna(datetime.today().strftime('%Y-%m-%d'), inplace=True)\n",
    "\n",
    "# data.to_csv(\"articles_titles_cleaned.csv\",encoding='utf-8-sig', index=False)\n",
    "\n",
    "date_today = datetime.now().strftime(\"%Y%m%d\")\n",
    "data.to_csv(f\"articles_titles_cleaned_{date_today}.csv\", encoding='utf-8-sig', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04117bea",
   "metadata": {},
   "source": [
    "# Hugging Face Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf2ba0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Specify the model name\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to classify text\n",
    "def classify_text(text):\n",
    "    # Check if the text is a string\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize the text\n",
    "        inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Get the predicted class (the one with the highest score)\n",
    "        predicted_class = torch.argmax(outputs.logits).item()\n",
    "\n",
    "        return predicted_class\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('articles_titles_cleaned.csv')\n",
    "\n",
    "# Apply the function to the 'Title' column and create a new column 'Model_title'\n",
    "df['Model_title'] = df['Title'].apply(classify_text)\n",
    "\n",
    "# Save the dataframe to a new CSV file\n",
    "df.to_csv('file_with_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7147d2",
   "metadata": {},
   "source": [
    "# Hugging Face Zero Shot Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad1fe459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Classifying: 100%|███████████████████████████████████████████████████████████████████| 519/519 [03:52<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# List of possible classes (i.e., the topics you're interested in)\n",
    "classes = [\"Tech & Gadgets\", \"Automobiles & EVs\", \"Government & Policy\", \"Business & Finance\", \"Gaming\", \"Natural Disasters\"]\n",
    "\n",
    "# Initialize the zero-shot-classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Function to classify text\n",
    "def classify_text(text):\n",
    "    # Make sure the text is a string\n",
    "    if isinstance(text, str):\n",
    "        # Use the pipeline to classify the text\n",
    "        result = classifier(text, classes)\n",
    "        # Get the label of the class with the highest score\n",
    "        predicted_class = result['labels'][0]\n",
    "        return predicted_class\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('articles_titles_cleaned.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Apply the function to the 'Title' column and create a new column 'Model_title'\n",
    "# Use tqdm to display progress\n",
    "tqdm.pandas(desc=\"Classifying\")\n",
    "df['Model_title'] = df['Title'].progress_apply(classify_text)\n",
    "\n",
    "# Save the dataframe to a new CSV file\n",
    "df.to_csv('file_with_predictions_zero_shot.csv' ,encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60570189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79934fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6219daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.engadget.com/ scraped successfully.\n",
      "{'Source': 'Engadget', 'Title': 'What we bought: Engadget’s favorite backpacks', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Amazon builds new Florida satellite facility for its Starlink rival', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Reddit takes control of popular subreddit that protested API changes', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Apple supplier TSMC delays Arizona chip production to 2025', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'The best portable Bluetooth speakers for 2023', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Apple supplier TSMC delays Arizona chip production to 2025', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'The best portable Bluetooth speakers for 2023', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': '‘Star Trek: Strange New Worlds’ drops its ‘Lower Decks’ crossover early', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"'Oppenheimer' review: Sympathy for the destroyer of worlds\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'ExpressVPN review: Our favorite for gaming and streaming', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Tesla offers customers one-time Full Self-Driving transfer until September 30th', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Twitter is limiting the number of DMs unverified users can send', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"ChatGPT's Android app arrives in the last week of July\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Google rolls out Android app streaming to Chromebooks following beta', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Amazon is reportedly making employees relocate for return-to-office', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"OpenAI's trust and safety lead is leaving the company\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Reddit takes control of popular subreddit that protested API changes', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Amazon builds new Florida satellite facility for its Starlink rival', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'The best budget gaming laptops for 2023', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'Apple supplier TSMC delays Arizona chip production to 2025', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"Apple's 10.2-inch iPad drops back to $250, plus the rest of the week's best tech deals\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"Redditors troll an AI content farm into covering a fake 'WoW' feature\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"Amazon's Fire TV Stick 4K Max is nearly half off right now\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'What we bought: Engadget’s favorite backpacks', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': \"Engadget Podcast: How AI created a 'South Park' episode around us\", 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'The best portable Bluetooth speakers for 2023', 'Summary': 'No summary available', 'Date': 'No date available'}\n",
      "{'Source': 'Engadget', 'Title': 'The Morning After: What to expect at Samsung’s Unpacked 2023 event next week', 'Summary': 'No summary available', 'Date': 'No date available'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def create_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "def extract_engadget_data(soup):\n",
    "    news_items = []\n",
    "\n",
    "    for news_item in soup.find_all('article', recursive=True):\n",
    "        heading_tag = None\n",
    "\n",
    "        # Find the appropriate heading tag\n",
    "        for i in range(1, 7):\n",
    "            if news_item.find(f'h{i}'):\n",
    "                heading_tag = news_item.find(f'h{i}')\n",
    "                break\n",
    "        \n",
    "        if heading_tag and heading_tag.a:\n",
    "            title = heading_tag.a.text.strip()\n",
    "\n",
    "            summary_element = news_item.find('p')\n",
    "            summary = summary_element.text.strip() if summary_element else 'No summary available'\n",
    "            \n",
    "            date_element = news_item.find('time') or news_item.find('span', {'class': 'date'})  # Replace 'date' with the actual class name\n",
    "            date = date_element.text.strip() if date_element else 'No date available'\n",
    "\n",
    "            news_items.append({\"Source\": \"Engadget\", \"Title\": title, \"Summary\": summary, \"Date\": date})\n",
    "    \n",
    "    return news_items\n",
    "\n",
    "def scrape_engadget(url):\n",
    "    soup = create_soup(url)\n",
    "    if soup:\n",
    "        data = extract_engadget_data(soup)\n",
    "        print(f\"{url} scraped successfully.\")\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Testing\n",
    "url = 'https://www.engadget.com/'\n",
    "data = scrape_engadget(url)\n",
    "for item in data:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bd25291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Source': 'SCMP', 'Title': 'China targets invasive plants and animals in 3-year crackdown', 'Article URL': 'https://www.scmp.com/news/china/article/3228649/china-targets-invasive-plants-and-animals-3-year-crackdown?module=live&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'Putin hosts Belarus’ Lukashenko, calls Ukraine’s counteroffensive a failure', 'Article URL': 'https://www.scmp.com/news/world/russia-central-asia/article/3228657/putin-hosts-lukashenko-calls-counteroffensive-ukraine-failure?module=live&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'School stadium roof collapses in China, trapping at least 10', 'Article URL': 'https://www.scmp.com/news/china/article/3228655/school-stadium-roof-collapses-china-trapping-least-10?module=live&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'Beijing detains waste firm workers in fake air pollution data case', 'Article URL': 'https://www.scmp.com/news/china/article/3228639/beijing-detains-waste-firm-workers-fake-air-pollution-data-case?module=live&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'Hong Kong woman charged in Japan with smuggling HK$82 million worth of drugs', 'Article URL': 'https://www.scmp.com/news/hong-kong/law-and-crime/article/3228653/hong-kong-convenience-store-worker-charged-smuggling-almost-hk82-million-drugs-japan?module=live&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'The US has suspended the Wuhan Institute of Virology’s access to American federal funding. Photo: AFP', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'The message in the US funding cut for China’s Wuhan Institute of Virology', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'Did the US fund risky research at the Wuhan Institute of Virology?', 'Article URL': 'https://www.scmp.com/news/china/science/article/3148833/debate-over-claim-coronavirus-came-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'The US has suspended the Wuhan Institute of Virology’s access to American federal funding. Photo: AFP', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'The message in the US funding cut for China’s Wuhan Institute of Virology', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': '', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'The message in the US funding cut for China’s Wuhan Institute of Virology', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228640/mutual-distrust-message-us-funding-cut-chinas-wuhan-institute-virology?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'African exports to China plunge amid property market slowdown', 'Article URL': 'https://www.scmp.com/news/china/diplomacy/article/3228642/african-exports-china-plunge-amid-property-market-slowdown-and-sluggish-economic-recovery?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'School stadium roof collapses in China, trapping at least 10', 'Article URL': 'https://www.scmp.com/news/china/article/3228655/school-stadium-roof-collapses-china-trapping-least-10?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': '', 'Article URL': 'https://www.scmp.com/news/china/article/3228655/school-stadium-roof-collapses-china-trapping-least-10'}\n",
      "{'Source': 'SCMP', 'Title': 'School stadium roof collapses in China, trapping at least 10', 'Article URL': 'https://www.scmp.com/news/china/article/3228655/school-stadium-roof-collapses-china-trapping-least-10'}\n",
      "{'Source': 'SCMP', 'Title': 'Legal action by Hong Kong Golf Club won’t sway officials on flats plan: John Lee', 'Article URL': 'https://www.scmp.com/news/hong-kong/hong-kong-economy/article/3228638/hong-kongs-john-lee-brushes-possible-legal-action-golf-club-over-plan-build-public-housing-oldest?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'Legal action by Hong Kong Golf Club won’t sway officials on flats plan: John Lee', 'Article URL': 'https://www.scmp.com/news/hong-kong/hong-kong-economy/article/3228638/hong-kongs-john-lee-brushes-possible-legal-action-golf-club-over-plan-build-public-housing-oldest?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': '', 'Article URL': 'https://www.scmp.com/news/hong-kong/hong-kong-economy/article/3228638/hong-kongs-john-lee-brushes-possible-legal-action-golf-club-over-plan-build-public-housing-oldest?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'China targets invasive plants and animals in 3-year crackdown', 'Article URL': 'https://www.scmp.com/news/china/article/3228649/china-targets-invasive-plants-and-animals-3-year-crackdown?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': '', 'Article URL': 'https://www.scmp.com/news/china/article/3228649/china-targets-invasive-plants-and-animals-3-year-crackdown?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': 'China targets invasive plants and animals in 3-year crackdown', 'Article URL': 'https://www.scmp.com/news/china/article/3228649/china-targets-invasive-plants-and-animals-3-year-crackdown?module=lead_hero_story&pgtype=homepage'}\n",
      "{'Source': 'SCMP', 'Title': '', 'Article URL': 'https://www.scmp.com/news/china/article/3228649/china-targets-invasive-plants-and-animals-3-year-crackdown?module=lead_hero_story&pgtype=homepage'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def create_soup(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return BeautifulSoup(response.text, 'html.parser') if response.status_code == 200 else None\n",
    "\n",
    "def scrape_scmp(url, headers):\n",
    "    soup = create_soup(url, headers)\n",
    "    data = []\n",
    "\n",
    "    if soup:\n",
    "        news_items = soup.find_all('a')\n",
    "\n",
    "        for news_item in news_items:\n",
    "            # Check if 'href' attribute exists and 'scmp.com/news/' is in 'href'\n",
    "            if 'href' in news_item.attrs and 'scmp.com/news/' in news_item['href']:\n",
    "                title = news_item.text.strip()\n",
    "                article_url = news_item['href']\n",
    "\n",
    "                data.append({\"Source\": \"SCMP\", \"Title\": title, \"Article URL\": article_url})\n",
    "\n",
    "        # Additional loop for div tags\n",
    "        div_news_items = soup.find_all('div', class_='link__headline headline')\n",
    "\n",
    "        for div_news_item in div_news_items:\n",
    "            title = div_news_item.text.strip()\n",
    "            # No URL available from div tag\n",
    "            data.append({\"Source\": \"SCMP\", \"Title\": title, \"Article URL\": \"URL not available\"})\n",
    "    else:\n",
    "        print(\"Error: Unable to create soup object.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Define headers\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# Scrape SCMP\n",
    "scmp_data = scrape_scmp(\"https://www.scmp.com/\", HEADERS)\n",
    "for news_item in scmp_data:\n",
    "    print(news_item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
